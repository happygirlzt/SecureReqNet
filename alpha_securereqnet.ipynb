{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/danaderp/SecureReqNet/blob/master/alpha_securereqnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeZw_wJ0fvvF"
   },
   "source": [
    "## Alpha-SecureReqNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zweGRad_d4va"
   },
   "outputs": [],
   "source": [
    "#danaderp May6'19\n",
    "#Prediction For Main Issues Data Set \n",
    "#alpha-SecureReqNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tV4BxbkCfu09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happygirlzt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/dict_vectorizer.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "englishStemmer=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wMymf9NRaYNc",
    "outputId": "7daddf17-fc70-498d-d268-99f7a16d67b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/happygirlzt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "URHlMuyvgZsW",
    "outputId": "7161654a-f9e1-4ed0-e6a3-2e1d7e18a190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "#Importing Neural Dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dot, Input, Dense, Reshape, LSTM, Conv2D, Flatten, MaxPooling1D, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.layers import Embedding, Multiply, Subtract\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMqMwL02giiq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Ptsx9ghpqj_G",
    "outputId": "e4a072e0-27c7-4d19-fe16-2de980b90173"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGe5_Jx4K5WO"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/content/gdrive/My Drive/Colab Notebooks/secure-req-net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjEYU6Gw-K26"
   },
   "outputs": [],
   "source": [
    "#! unzip /content/gdrive/My\\ Drive/Colab\\ Notebooks/secure-req-net/datasets/augmented_dataset/augmented_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hQ6ctNB_uZ3"
   },
   "outputs": [],
   "source": [
    "#! cp -r issues/ /content/gdrive/My\\ Drive/Colab\\ Notebooks/secure-req-net/datasets/augmented_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.cells:\n",
    "                if cell.cell_type == 'code':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPfRbyEiGdx-"
   },
   "outputs": [],
   "source": [
    "from data.read_data import Dynamic_Dataset\n",
    "from data.read_data import Processing_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sPpIvKEJQ5v"
   },
   "source": [
    "### Loading word embeddings from previous compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_risxO7JRmy"
   },
   "outputs": [],
   "source": [
    "path = \"data/augmented_dataset/\" #Place here the dataset you want to process\n",
    "process_unit = Processing_Dataset(path)\n",
    "ground_truth = process_unit.get_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "0XUh1VSTJqX2",
    "outputId": "ad2b28fc-7f93-4b75-9fd5-84ddb07cfbcf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11612 104510\n",
      "('(1,0)', 'An issue was discovered in the cantata-mounter D-Bus service in Cantata through 2.3.1. The mount target path check in mounter.cpp `mpOk()` is insufficient. A regular user can consequently mount a CIFS filesystem anywhere (e.g., outside of the /home directory tree) by passing directory traversal sequences such as a home/../usr substring.') ('(1,0)', 'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/')\n"
     ]
    }
   ],
   "source": [
    "dataset = Dynamic_Dataset(ground_truth, path)\n",
    "test, train = process_unit.get_test_and_training(ground_truth)\n",
    "print(len(test),len(train))\n",
    "print(test[0],train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbNp-1h0KATi"
   },
   "outputs": [],
   "source": [
    "#Preprocesing Corpora\n",
    "# embeddings = Embeddings\n",
    "max_words = 5000 #<------- [Parameter]\n",
    "pre_corpora_train = [doc for doc in train if len(doc[1])< max_words]\n",
    "pre_corpora_test = [doc for doc in test if len(doc[1])< max_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wCCf9WmwKFI-",
    "outputId": "8104a66d-f3cc-456b-8806-ef635620c2c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103866 11549\n"
     ]
    }
   ],
   "source": [
    "print(len(pre_corpora_train),len(pre_corpora_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3tbLvCR7KSmb"
   },
   "outputs": [],
   "source": [
    "#Loading embeddings\n",
    "# embed_path = '/content/gdrive/My Drive/Colab Notebooks/secure-req-net/datasets/augmented_dataset/word_embeddings-embed_size_100-epochs_100.csv'\n",
    "# embeddings_dict = embeddings.get_embeddings_dict(embed_path)\n",
    "# Does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17227\n",
      "Index(['use', 'user', 'version', 'test', 'file', 'secur', 'vulner', 'issu',\n",
      "       'allow', 'new',\n",
      "       ...\n",
      "       'enfield', 'hvidovr', 'madura', 'nonotak', 'bazeley', 'kunnam',\n",
      "       'steelesvill', 'pessoa', 'morisada', 'kuttin'],\n",
      "      dtype='object', length=17227)\n"
     ]
    }
   ],
   "source": [
    "# Rewrite cell above\n",
    "import pandas as pd\n",
    "embed_path = 'data/word_embeddings-embed_size_100-epochs_100.csv'\n",
    "df = pd.read_csv(embed_path)\n",
    "#print(df)\n",
    "cols = df.columns[1:]\n",
    "\n",
    "print(len(cols))\n",
    "print(cols)\n",
    "df.reset_index()\n",
    "embeddings_dict = {}\n",
    "for i in range(len(cols)):\n",
    "    #embedding_dict[cols[i]]\n",
    "    embeddings_dict[cols[i]] = list(df.iloc[:,i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 17228)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_dict['use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_corpora_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_corpora_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_train_mod = []\n",
    "Y_train_data=[]\n",
    "\n",
    "for row in pre_corpora_train:\n",
    "    corpora_train_mod.append(row[1])\n",
    "    Y_train_data.append(row[0])\n",
    "    \n",
    "corpora_test_mod=[]\n",
    "Y_test_data=[]\n",
    "for row in pre_corpora_test:\n",
    "    corpora_test_mod.append(row[1])\n",
    "    Y_test_data.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpora_train_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mUT1jXMKaR2"
   },
   "outputs": [],
   "source": [
    "#corpora_train = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_train]#vectorization Inputs\n",
    "#corpora_train=vectorizer.fit_transform(corpora_train_mod)\n",
    "#corpora_test=vectorizer.fit_transform(corpora_test_mod)\n",
    "#corpora_test = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_test]#vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/happygirlzt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/happygirlzt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/happygirlzt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re, nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103866\n",
      "---- Nomalizing ----\n",
      "103866\n",
      "Sentences 0 of 103866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happygirlzt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences 1000 of 103866\n",
      "Sentences 2000 of 103866\n",
      "Sentences 3000 of 103866\n",
      "Sentences 4000 of 103866\n",
      "Sentences 5000 of 103866\n",
      "Sentences 6000 of 103866\n",
      "Sentences 7000 of 103866\n",
      "Sentences 8000 of 103866\n",
      "Sentences 9000 of 103866\n",
      "Sentences 10000 of 103866\n",
      "Sentences 11000 of 103866\n",
      "Sentences 12000 of 103866\n",
      "Sentences 13000 of 103866\n",
      "Sentences 14000 of 103866\n",
      "Sentences 15000 of 103866\n",
      "Sentences 16000 of 103866\n",
      "Sentences 17000 of 103866\n",
      "Sentences 18000 of 103866\n",
      "Sentences 19000 of 103866\n",
      "Sentences 20000 of 103866\n",
      "Sentences 21000 of 103866\n",
      "Sentences 22000 of 103866\n",
      "Sentences 23000 of 103866\n",
      "Sentences 24000 of 103866\n",
      "Sentences 25000 of 103866\n",
      "Sentences 26000 of 103866\n",
      "Sentences 27000 of 103866\n",
      "Sentences 28000 of 103866\n",
      "Sentences 29000 of 103866\n",
      "Sentences 30000 of 103866\n",
      "Sentences 31000 of 103866\n",
      "Sentences 32000 of 103866\n",
      "Sentences 33000 of 103866\n",
      "Sentences 34000 of 103866\n",
      "Sentences 35000 of 103866\n",
      "Sentences 36000 of 103866\n",
      "Sentences 37000 of 103866\n",
      "Sentences 38000 of 103866\n",
      "Sentences 39000 of 103866\n",
      "Sentences 40000 of 103866\n",
      "Sentences 41000 of 103866\n",
      "Sentences 42000 of 103866\n",
      "Sentences 43000 of 103866\n",
      "Sentences 44000 of 103866\n",
      "Sentences 45000 of 103866\n",
      "Sentences 46000 of 103866\n",
      "Sentences 47000 of 103866\n",
      "Sentences 48000 of 103866\n",
      "Sentences 49000 of 103866\n",
      "Sentences 50000 of 103866\n",
      "Sentences 51000 of 103866\n",
      "Sentences 52000 of 103866\n",
      "Sentences 53000 of 103866\n",
      "Sentences 54000 of 103866\n",
      "Sentences 55000 of 103866\n",
      "Sentences 56000 of 103866\n",
      "Sentences 57000 of 103866\n",
      "Sentences 58000 of 103866\n",
      "Sentences 59000 of 103866\n",
      "Sentences 60000 of 103866\n",
      "Sentences 61000 of 103866\n",
      "Sentences 62000 of 103866\n",
      "Sentences 63000 of 103866\n",
      "Sentences 64000 of 103866\n",
      "Sentences 65000 of 103866\n",
      "Sentences 66000 of 103866\n",
      "Sentences 67000 of 103866\n",
      "Sentences 68000 of 103866\n",
      "Sentences 69000 of 103866\n",
      "Sentences 70000 of 103866\n",
      "Sentences 71000 of 103866\n",
      "Sentences 72000 of 103866\n",
      "Sentences 73000 of 103866\n",
      "Sentences 74000 of 103866\n",
      "Sentences 75000 of 103866\n",
      "Sentences 76000 of 103866\n",
      "Sentences 77000 of 103866\n",
      "Sentences 78000 of 103866\n",
      "Sentences 79000 of 103866\n",
      "Sentences 80000 of 103866\n",
      "Sentences 81000 of 103866\n",
      "Sentences 82000 of 103866\n",
      "Sentences 83000 of 103866\n",
      "Sentences 84000 of 103866\n",
      "Sentences 85000 of 103866\n",
      "Sentences 86000 of 103866\n",
      "Sentences 87000 of 103866\n",
      "Sentences 88000 of 103866\n",
      "Sentences 89000 of 103866\n",
      "Sentences 90000 of 103866\n",
      "Sentences 91000 of 103866\n",
      "Sentences 92000 of 103866\n",
      "Sentences 93000 of 103866\n",
      "Sentences 94000 of 103866\n",
      "Sentences 95000 of 103866\n",
      "Sentences 96000 of 103866\n",
      "Sentences 97000 of 103866\n",
      "Sentences 98000 of 103866\n",
      "Sentences 99000 of 103866\n",
      "Sentences 100000 of 103866\n",
      "Sentences 101000 of 103866\n",
      "Sentences 102000 of 103866\n",
      "Sentences 103000 of 103866\n",
      "11549\n",
      "---- Nomalizing ----\n",
      "11549\n",
      "Sentences 0 of 11549\n",
      "Sentences 1000 of 11549\n",
      "Sentences 2000 of 11549\n",
      "Sentences 3000 of 11549\n",
      "Sentences 4000 of 11549\n",
      "Sentences 5000 of 11549\n",
      "Sentences 6000 of 11549\n",
      "Sentences 7000 of 11549\n",
      "Sentences 8000 of 11549\n",
      "Sentences 9000 of 11549\n",
      "Sentences 10000 of 11549\n",
      "Sentences 11000 of 11549\n"
     ]
    }
   ],
   "source": [
    "num_features=100\n",
    "\n",
    "def nomalizer(sent):\n",
    "    only_letters=re.sub(\"[^a-zA-Z]\", \" \", sent)\n",
    "    tokens=nltk.word_tokenize(only_letters)[2:]\n",
    "    lower_case=[l.lower() for l in tokens]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    wordnet_lemmatizer=WordNetLemmatizer()\n",
    "    filtered_result=list(filter(lambda l: l not in stop_words, lower_case))\n",
    "    lemmas=[wordnet_lemmatizer.lemmatize(t) for t in filtered_result]\n",
    "    return lemmas\n",
    "\n",
    "# Generate a sentence vector by averaging words embeddings in a sentence\n",
    "def generate_sentence_vec(sentence, embeddings_dict, num_features):\n",
    "    sentence_vec=np.zeros(num_features,dtype=\"float32\")\n",
    "    num_words = 0\n",
    "    \n",
    "    embeddings_set=set(embeddings_dict.keys())\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word in embeddings_set:\n",
    "            num_words+=1\n",
    "            sentence_vec=np.add(sentence_vec, embeddings_dict[word])\n",
    "    \n",
    "    sentence_vec=np.divide(sentence_vec,num_words)\n",
    "    #print(sentence_vec)\n",
    "    return sentence_vec\n",
    "\n",
    "# Generate all senteneces vectors\n",
    "def generate_average_sentences_vec(sentences,embeddings_dict,num_features):\n",
    "    count=0\n",
    "    total_sent=len(sentences)\n",
    "    sentences_vec=np.zeros((len(sentences),num_features),dtype=\"float32\")\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if count % 1000 == 0:\n",
    "            print(\"Sentences {} of {}\".format(count,total_sent))\n",
    "\n",
    "        sentences_vec[count] = generate_sentence_vec(sentence, embeddings_dict, num_features)\n",
    "        count+=1\n",
    "\n",
    "    return sentences_vec\n",
    "\n",
    "def get_sentence_vectors(raw_data):\n",
    "    data = []\n",
    "    print(len(raw_data))\n",
    "    print(\"---- Nomalizing ----\")\n",
    "    for sent in raw_data:\n",
    "        data.append(nomalizer(sent))\n",
    "    \n",
    "    print(len(data))\n",
    "    X=generate_average_sentences_vec(data, embeddings_dict, num_features)\n",
    "    return X\n",
    "\n",
    "X_train_data = get_sentence_vectors(corpora_train_mod)\n",
    "X_test_data=get_sentence_vectors(corpora_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qd4ObDh0KbHM"
   },
   "outputs": [],
   "source": [
    "target_train = [[int(list(doc[0])[1]),int(list(doc[0])[3])] for doc in pre_corpora_train]#vectorization Output\n",
    "target_test = [[int(list(doc[0])[1]),int(list(doc[0])[3])]for doc in pre_corpora_test]#vectorization Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6GKIcOqKejD"
   },
   "outputs": [],
   "source": [
    "max_len_sentences_train = max([len(doc) for doc in X_train_data]) #<------- [Parameter]\n",
    "max_len_sentences_test = max([len(doc) for doc in X_test_data]) #<------- [Parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "84Y6sWgPKgkj",
    "outputId": "faf14c6d-926f-4256-b737-ce2541e30b73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. Sentence # words: 100\n"
     ]
    }
   ],
   "source": [
    "max_len_sentences = max(max_len_sentences_train,max_len_sentences_test)\n",
    "print(\"Max. Sentence # words:\",max_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_bTQ2ANKhjG"
   },
   "outputs": [],
   "source": [
    "min_len_sentences_train = min([len(doc) for doc in X_train_data]) #<------- [Parameter]\n",
    "min_len_sentences_test = min([len(doc) for doc in X_test_data]) #<------- [Parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DG6fdraDKjau",
    "outputId": "8f2ff01c-1374-465a-ca7c-c847320b1576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. Sentence # words: 100\n"
     ]
    }
   ],
   "source": [
    "min_len_sentences = max(min_len_sentences_train,min_len_sentences_test)\n",
    "print(\"Min. Sentence # words:\",min_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osMqB7LMKlCO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "embed_size = np.size(X_train_data[0][0])\n",
    "print(embed_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKY-ieldfnVQ"
   },
   "source": [
    "### Designing Baseline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfQ2znRCK0MS"
   },
   "outputs": [],
   "source": [
    "#BaseLine Architecture <-------\n",
    "embeddigs_cols = embed_size\n",
    "input_sh = (max_len_sentences,embeddigs_cols,1)\n",
    "#Selecting filters? \n",
    "#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function\n",
    "#https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional\n",
    "\n",
    "N_filters = 128 # <-------- [HyperParameter] Powers of 2 Numer of Features\n",
    "K = 2 # <-------- [HyperParameter] Number of Classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZpBx4mEgK4oa",
    "outputId": "7f560cd1-0ddd-445d-bf57-61897832e267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "glpiGw14K-ch",
    "outputId": "32e23066-c2fd-451d-9656-6975beb6c229"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 94, 1, 32])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_input = Input(shape = input_sh)\n",
    "# 1st Convolutional Layer Convolutional Layer (7-gram)\n",
    "conv_1_layer = Conv2D(filters=32, input_shape=input_sh, activation='relu', \n",
    "                      kernel_size=(7,embeddigs_cols), padding='valid')(gram_input)\n",
    "conv_1_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CDLlKGWFLBQR",
    "outputId": "21426f83-311e-40d2-e163-1de09a6c1f37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1, 1, 32])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Pooling \n",
    "max_1_pooling = MaxPooling2D(pool_size=((max_len_sentences-7+1),1), strides=None, padding='valid')(conv_1_layer)\n",
    "max_1_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NIPAYP28LDXv",
    "outputId": "1e24617f-9be5-41e9-faf7-11fc4f581204"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 32])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected_1_gram = Flatten()(max_1_pooling)\n",
    "fully_connected_1_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YL4Rk9RyLFBF",
    "outputId": "c80a8898-d8f7-436c-849a-401f0e737a05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 32, 1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_connected_1_gram = Reshape((32, 1, 1))(fully_connected_1_gram)\n",
    "fully_connected_1_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "13c97VKNLIDs",
    "outputId": "daa22b71-3994-4d3d-e2aa-31dac4d3a07f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 28, 1, 64])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd Convolutional Layer (5-gram)\n",
    "conv_2_layer = Conv2D(filters=64, kernel_size=(5,1), activation='relu', \n",
    "                      padding='valid')(fully_connected_1_gram)\n",
    "conv_2_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FoIm4mTZLKsx",
    "outputId": "7b1310c0-5e2d-4ceb-f9e2-3944c6162bbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1, 1, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_2_pooling = MaxPooling2D(pool_size=((32-5+1),1), strides=None, padding='valid')(conv_2_layer)\n",
    "max_2_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3BUO38gRLMoy",
    "outputId": "9d497c9c-1e1f-491c-d2f1-0ea6030b9462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected_2_gram = Flatten()(max_2_pooling)\n",
    "fully_connected_2_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m3t8vnrrLPDi",
    "outputId": "a9464f2a-ae71-4dcf-b2ab-306fc8cbaec8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64, 1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_connected_2_gram = Reshape((64, 1, 1))(fully_connected_2_gram)\n",
    "fully_connected_2_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TRBrLT6hLQ4x",
    "outputId": "aa9efea5-1983-4bc4-b6f5-2bd84e25b5f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 62, 1, 128])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd Convolutional Layer (3-gram)\n",
    "conv_3_layer =  Conv2D(filters=128, kernel_size=(3,1), activation='relu', \n",
    "                      padding='valid')(fully_connected_2_gram)\n",
    "conv_3_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3fqEy0OvLTo3",
    "outputId": "6599672b-dd13-47ed-b0b9-e3737456664a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 60, 1, 128])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4th Convolutional Layer (3-gram)\n",
    "conv_4_layer = Conv2D(filters=128, kernel_size=(3,1), activation='relu', \n",
    "                     padding='valid')(conv_3_layer)\n",
    "conv_4_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wVv4RFv6LYYt",
    "outputId": "30eb2c76-c0e0-4153-8428-73f3493d5074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 58, 1, 64])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5th Convolutional Layer (3-gram)\n",
    "conv_5_layer = Conv2D(filters=64, kernel_size=(3,1), activation='relu', \n",
    "                     padding='valid')(conv_4_layer)\n",
    "conv_5_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l4hqFvdHLaRZ",
    "outputId": "579163a8-4e80-42b4-bfad-0d467ac3eb31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1, 1, 64])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Pooling\n",
    "max_5_pooling = MaxPooling2D(pool_size=(58,1), strides=None, padding='valid')(conv_5_layer)\n",
    "max_5_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tbgwf1kgLdzW",
    "outputId": "3b76a2b2-88a1-42db-d726-4c3c09de755a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected = Flatten()(max_5_pooling)\n",
    "fully_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bc0USw7yLiBk",
    "outputId": "f5cbed89-d7a1-4938-c57f-0d40e8971b96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 32])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st Fully Connected Layer\n",
    "deep_dense_1_layer = Dense(32, activation='relu')(fully_connected)\n",
    "deep_dense_1_layer = Dropout(0.2)(deep_dense_1_layer) # <-------- [HyperParameter]\n",
    "deep_dense_1_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cPCwpofQLj5j",
    "outputId": "61eda5c0-c42b-4a99-d87a-ffc121e02f00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 32])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd Fully Connected Layer\n",
    "deep_dense_2_layer = Dense(32, activation='relu')(deep_dense_1_layer)\n",
    "deep_dense_2_layer = Dropout(0.2)(deep_dense_2_layer) # <-------- [HyperParameter]\n",
    "deep_dense_2_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4PK2LvkbLrFJ",
    "outputId": "f23d53c1-b4cb-4b1f-9aec-1c4cb69c526d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 16])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd Fully Connected Layer\n",
    "deep_dense_3_layer = Dense(16, activation='relu')(deep_dense_2_layer)\n",
    "deep_dense_3_layer = Dropout(0.2)(deep_dense_3_layer) # <-------- [HyperParameter]\n",
    "deep_dense_3_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjjeoJYGLwFp"
   },
   "outputs": [],
   "source": [
    "predictions = Dense(K, activation='softmax')(deep_dense_3_layer)\n",
    "#Criticality Model\n",
    "criticality_network = Model(inputs=[gram_input],outputs=[predictions]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "wmoUPuPqL2z3",
    "outputId": "7c749f96-777c-4cfb-afe0-b364195506d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 1, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 94, 1, 32)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 1, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 1, 64)         384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 64, 1, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 62, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 1, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 58, 1, 64)         24640     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 78,770\n",
      "Trainable params: 78,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(criticality_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1v_kHaUL6mt"
   },
   "outputs": [],
   "source": [
    "#Seting up the Model\n",
    "criticality_network.compile(optimizer='adam',loss='binary_crossentropy',\n",
    "                                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQwpKXySMGBH"
   },
   "source": [
    "### Training the criticality network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-2N8Q80L-Yg"
   },
   "outputs": [],
   "source": [
    "#Data set organization\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0AY6LJaMRre"
   },
   "outputs": [],
   "source": [
    "#Memoization \n",
    "file_corpora_train_x = path.join(mkdtemp(), 'train_x.dat') #Update per experiment\n",
    "file_corpora_test_x = path.join(mkdtemp(), 'test_x.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLzqqGd7MUwA"
   },
   "outputs": [],
   "source": [
    "#Shaping\n",
    "shape_train_x = (len(X_train_data),max_len_sentences,embeddigs_cols,1)\n",
    "shape_test_x = (len(X_test_data),max_len_sentences,embeddigs_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWvQjALqMZL4"
   },
   "outputs": [],
   "source": [
    "#Data sets\n",
    "corpora_train_x = np.memmap(\n",
    "        filename = file_corpora_train_x, \n",
    "        dtype='float32', \n",
    "        mode='w+', \n",
    "        shape = shape_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ivCP2HQlMdFQ"
   },
   "outputs": [],
   "source": [
    "corpora_test_x = np.memmap( #Test Corpora (for future evaluation)\n",
    "        filename = file_corpora_test_x, \n",
    "        dtype='float32', \n",
    "        mode='w+', \n",
    "        shape = shape_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZCT_mVRMflg"
   },
   "outputs": [],
   "source": [
    "target_train_y = np.array(target_train) #Train Target\n",
    "target_test_y = np.array(target_test) #Test Target (for future evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmIKpBK-MkkK",
    "outputId": "2f06ef40-0a27-4ff7-a3b1-de0f3147c31f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103866, 100, 1, 1) (103866, 2)\n"
     ]
    }
   ],
   "source": [
    "print(corpora_train_x.shape, target_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TgDiguWEMnm0",
    "outputId": "3fc51011-77f2-4172-a39d-028a7936db81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11549, 100, 1, 1) (11549, 2)\n"
     ]
    }
   ],
   "source": [
    "print(corpora_test_x.shape,target_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gtb-8-VMoYL"
   },
   "outputs": [],
   "source": [
    "#Reshaping Train Inputs\n",
    "for doc in range(len(X_train_data)):\n",
    "    #print(corpora_train[doc].shape[1])\n",
    "    for words_rows in range(X_train_data[doc].shape[0]):\n",
    "        embed_flatten = np.array(X_train_data[doc][words_rows]).flatten() #<--- Capture doc and word\n",
    "        for embedding_cols in range(embed_flatten.shape[0]):\n",
    "            corpora_train_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9hH0IbAMo5L"
   },
   "outputs": [],
   "source": [
    "#Reshaping Test Inputs (for future evaluation)\n",
    "for doc in range(len(X_test_data)):\n",
    "    for words_rows in range(X_test_data[doc].shape[0]):\n",
    "        embed_flatten = np.array(X_test_data[doc][words_rows]).flatten() #<--- Capture doc and word\n",
    "        for embedding_cols in range(embed_flatten.shape[0]):\n",
    "            corpora_test_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgHs7WwRNCNe"
   },
   "outputs": [],
   "source": [
    "#CheckPoints\n",
    "filepath = \"best_model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqB2PbvYNHFV"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "mc = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "callbacks_list = [es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "30ahQNHeNIxg",
    "outputId": "d55fd7e2-a3b7-4adf-e744-2a1545d87af2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 83092 samples, validate on 20774 samples\n",
      "Epoch 1/10\n",
      "83008/83092 [============================>.] - ETA: 0s - loss: 5.8139 - accuracy: 0.6209\n",
      "Epoch 00001: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 25s 301us/sample - loss: 5.8147 - accuracy: 0.6209 - val_loss: 0.7420 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "82944/83092 [============================>.] - ETA: 0s - loss: 5.8216 - accuracy: 0.6204\n",
      "Epoch 00002: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 26s 310us/sample - loss: 5.8210 - accuracy: 0.6204 - val_loss: 0.7435 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "83072/83092 [============================>.] - ETA: 0s - loss: 5.8266 - accuracy: 0.6201\n",
      "Epoch 00003: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 26s 312us/sample - loss: 5.8261 - accuracy: 0.6201 - val_loss: 0.7536 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "83008/83092 [============================>.] - ETA: 0s - loss: 5.8191 - accuracy: 0.6205\n",
      "Epoch 00004: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 26s 316us/sample - loss: 5.8180 - accuracy: 0.6206 - val_loss: 0.7365 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "83072/83092 [============================>.] - ETA: 0s - loss: 5.8130 - accuracy: 0.6210\n",
      "Epoch 00005: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 26s 307us/sample - loss: 5.8140 - accuracy: 0.6209 - val_loss: 0.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "82944/83092 [============================>.] - ETA: 0s - loss: 5.8326 - accuracy: 0.6197\n",
      "Epoch 00006: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 26s 318us/sample - loss: 5.8322 - accuracy: 0.6197 - val_loss: 0.8167 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "83072/83092 [============================>.] - ETA: 0s - loss: 5.8253 - accuracy: 0.6202\n",
      "Epoch 00007: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 28s 334us/sample - loss: 5.8256 - accuracy: 0.6202 - val_loss: 0.8472 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "82880/83092 [============================>.] - ETA: 0s - loss: 5.8231 - accuracy: 0.6203\n",
      "Epoch 00008: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 26s 316us/sample - loss: 5.8239 - accuracy: 0.6203 - val_loss: 0.8935 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "82944/83092 [============================>.] - ETA: 0s - loss: 5.8264 - accuracy: 0.6201\n",
      "Epoch 00009: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 26s 309us/sample - loss: 5.8250 - accuracy: 0.6202 - val_loss: 0.9956 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "83008/83092 [============================>.] - ETA: 0s - loss: 5.8237 - accuracy: 0.6203\n",
      "Epoch 00010: val_accuracy did not improve from 0.00000\n",
      "83092/83092 [==============================] - 24s 289us/sample - loss: 5.8243 - accuracy: 0.6202 - val_loss: 1.0063 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#Model Fitting\n",
    "history = criticality_network.fit(\n",
    "            x = corpora_train_x, \n",
    "            y = target_train_y,\n",
    "            batch_size=64,\n",
    "            epochs=10, #5 <------ Hyperparameter\n",
    "            validation_split = 0.2,\n",
    "            callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xz8wz1ZPNKmP"
   },
   "outputs": [],
   "source": [
    "#Saving Training History\n",
    "df_history = pd.DataFrame.from_dict(history.history)\n",
    "df_history.to_csv('history_training.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "lmHTkzrZNQB7",
    "outputId": "9f7bdc82-5c94-47a3-9b9b-4b83ff83cb86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.814662</td>\n",
       "      <td>0.620866</td>\n",
       "      <td>0.742042</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.820971</td>\n",
       "      <td>0.620421</td>\n",
       "      <td>0.743463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.826114</td>\n",
       "      <td>0.620108</td>\n",
       "      <td>0.753577</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.818010</td>\n",
       "      <td>0.620601</td>\n",
       "      <td>0.736498</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.813973</td>\n",
       "      <td>0.620890</td>\n",
       "      <td>0.786091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  5.814662  0.620866  0.742042           0.0\n",
       "1  5.820971  0.620421  0.743463           0.0\n",
       "2  5.826114  0.620108  0.753577           0.0\n",
       "3  5.818010  0.620601  0.736498           0.0\n",
       "4  5.813973  0.620890  0.786091           0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criticality_network.save(filepath)\n",
    "df_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2FraZbmNWjH"
   },
   "outputs": [],
   "source": [
    "#Saving Test Data\n",
    "np.save('corpora_test_x.npy',corpora_test_x)\n",
    "np.save('target_test_y.npy',target_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_ZppHO9NcsA"
   },
   "source": [
    "### Partial Evaluation\n",
    "To make a deep evaluation, please refer to the \"evaluation\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "ngK3GrrRNp_h",
    "outputId": "223f1241-bb79-4130-99a4-ee02acf11bbf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Evaluation\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs2 = range(len(acc))\n",
    " \n",
    "plt.plot(epochs2, acc, 'b', label='Training')\n",
    "plt.plot(epochs2, val_acc, 'r', label='Validation')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs2, loss, 'b', label='Training')\n",
    "plt.plot(epochs2, val_loss, 'r', label='Validation')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "alpha-securereqnet.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
