{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/danaderp/SecureReqNet/blob/master/alpha_securereqnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeZw_wJ0fvvF"
   },
   "source": [
    "## Alpha-SecureReqNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zweGRad_d4va"
   },
   "outputs": [],
   "source": [
    "#danaderp May6'19\n",
    "#Prediction For Main Issues Data Set \n",
    "#alpha-SecureReqNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tV4BxbkCfu09"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "englishStemmer=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wMymf9NRaYNc",
    "outputId": "7daddf17-fc70-498d-d268-99f7a16d67b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/happygirlzt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "URHlMuyvgZsW",
    "outputId": "7161654a-f9e1-4ed0-e6a3-2e1d7e18a190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "#Importing Neural Dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dot, Input, Dense, Reshape, LSTM, Conv2D, Flatten, MaxPooling1D, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.layers import Embedding, Multiply, Subtract\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMqMwL02giiq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Ptsx9ghpqj_G",
    "outputId": "e4a072e0-27c7-4d19-fe16-2de980b90173"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGe5_Jx4K5WO"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/content/gdrive/My Drive/Colab Notebooks/secure-req-net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjEYU6Gw-K26"
   },
   "outputs": [],
   "source": [
    "#! unzip /content/gdrive/My\\ Drive/Colab\\ Notebooks/secure-req-net/datasets/augmented_dataset/augmented_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hQ6ctNB_uZ3"
   },
   "outputs": [],
   "source": [
    "#! cp -r issues/ /content/gdrive/My\\ Drive/Colab\\ Notebooks/secure-req-net/datasets/augmented_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.cells:\n",
    "                if cell.cell_type == 'code':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import notebook_utils.statistics.Embeddings as Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls nbpackage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPfRbyEiGdx-"
   },
   "outputs": [],
   "source": [
    "from data.read_data import Dynamic_Dataset\n",
    "from data.read_data import Processing_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sPpIvKEJQ5v"
   },
   "source": [
    "### Loading word embeddings from previous compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_risxO7JRmy"
   },
   "outputs": [],
   "source": [
    "path = \"data/augmented_dataset/\" #Place here the dataset you want to process\n",
    "process_unit = Processing_Dataset(path)\n",
    "ground_truth = process_unit.get_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "0XUh1VSTJqX2",
    "outputId": "ad2b28fc-7f93-4b75-9fd5-84ddb07cfbcf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11612 104510\n",
      "('(1,0)', 'Unspecified vulnerability in Android before 2016-09-01 has unknown impact and attack vectors.') ('(1,0)', 'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/')\n"
     ]
    }
   ],
   "source": [
    "dataset = Dynamic_Dataset(ground_truth, path)\n",
    "test, train = process_unit.get_test_and_training(ground_truth)\n",
    "print(len(test),len(train))\n",
    "print(test[0],train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbNp-1h0KATi"
   },
   "outputs": [],
   "source": [
    "#Preprocesing Corpora\n",
    "# embeddings = Embeddings\n",
    "max_words = 5000 #<------- [Parameter]\n",
    "pre_corpora_train = [doc for doc in train if len(doc[1])< max_words]\n",
    "pre_corpora_test = [doc for doc in test if len(doc[1])< max_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wCCf9WmwKFI-",
    "outputId": "8104a66d-f3cc-456b-8806-ef635620c2c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103874 11541\n"
     ]
    }
   ],
   "source": [
    "print(len(pre_corpora_train),len(pre_corpora_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3tbLvCR7KSmb"
   },
   "outputs": [],
   "source": [
    "#Loading embeddings\n",
    "# embed_path = '/content/gdrive/My Drive/Colab Notebooks/secure-req-net/datasets/augmented_dataset/word_embeddings-embed_size_100-epochs_100.csv'\n",
    "# embeddings_dict = embeddings.get_embeddings_dict(embed_path)\n",
    "# Does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17227\n",
      "Index(['use', 'user', 'version', 'test', 'file', 'secur', 'vulner', 'issu',\n",
      "       'allow', 'new',\n",
      "       ...\n",
      "       'enfield', 'hvidovr', 'madura', 'nonotak', 'bazeley', 'kunnam',\n",
      "       'steelesvill', 'pessoa', 'morisada', 'kuttin'],\n",
      "      dtype='object', length=17227)\n"
     ]
    }
   ],
   "source": [
    "# Rewrite cell above\n",
    "import pandas as pd\n",
    "embed_path = 'data/word_embeddings-embed_size_100-epochs_100.csv'\n",
    "df = pd.read_csv(embed_path)\n",
    "cols = df.columns[1:]\n",
    "\n",
    "print(len(cols))\n",
    "print(cols)\n",
    "df.reset_index()\n",
    "embeddings_dict = {}\n",
    "for i in range(len(cols)):\n",
    "    embeddings_dict[cols[i]] = list(df.iloc[:,i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_dict['use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_corpora_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '0', '1', ..., '0', '1', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora_train_mod = []\n",
    "\n",
    "y_train=[]\n",
    "for row in pre_corpora_train:\n",
    "    corpora_train_mod.append(row[1])\n",
    "    y_train.append(row[0][1])\n",
    "    \n",
    "np.asarray(y_train)\n",
    "corpora_test_mod=[]\n",
    "y_test=[]\n",
    "for row in pre_corpora_test:\n",
    "    corpora_test_mod.append(row[1])\n",
    "    y_test.append(row[0][1])\n",
    "    \n",
    "np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mUT1jXMKaR2"
   },
   "outputs": [],
   "source": [
    "#corpora_train = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_train]#vectorization Inputs\n",
    "#corpora_train=vectorizer.fit_transform(corpora_train_mod)\n",
    "#corpora_test=vectorizer.fit_transform(corpora_test_mod)\n",
    "#corpora_test = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_test]#vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/happygirlzt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/happygirlzt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/happygirlzt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re, nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103874\n",
      "---- Nomalizing ----\n",
      "103874\n",
      "Sentences 0 of 103874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happygirlzt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences 1000 of 103874\n",
      "Sentences 2000 of 103874\n",
      "Sentences 3000 of 103874\n",
      "Sentences 4000 of 103874\n",
      "Sentences 5000 of 103874\n",
      "Sentences 6000 of 103874\n",
      "Sentences 7000 of 103874\n",
      "Sentences 8000 of 103874\n",
      "Sentences 9000 of 103874\n",
      "Sentences 10000 of 103874\n",
      "Sentences 11000 of 103874\n",
      "Sentences 12000 of 103874\n",
      "Sentences 13000 of 103874\n",
      "Sentences 14000 of 103874\n",
      "Sentences 15000 of 103874\n",
      "Sentences 16000 of 103874\n",
      "Sentences 17000 of 103874\n",
      "Sentences 18000 of 103874\n",
      "Sentences 19000 of 103874\n",
      "Sentences 20000 of 103874\n",
      "Sentences 21000 of 103874\n",
      "Sentences 22000 of 103874\n",
      "Sentences 23000 of 103874\n",
      "Sentences 24000 of 103874\n",
      "Sentences 25000 of 103874\n",
      "Sentences 26000 of 103874\n",
      "Sentences 27000 of 103874\n",
      "Sentences 28000 of 103874\n",
      "Sentences 29000 of 103874\n",
      "Sentences 30000 of 103874\n",
      "Sentences 31000 of 103874\n",
      "Sentences 32000 of 103874\n",
      "Sentences 33000 of 103874\n",
      "Sentences 34000 of 103874\n",
      "Sentences 35000 of 103874\n",
      "Sentences 36000 of 103874\n",
      "Sentences 37000 of 103874\n",
      "Sentences 38000 of 103874\n",
      "Sentences 39000 of 103874\n",
      "Sentences 40000 of 103874\n",
      "Sentences 41000 of 103874\n",
      "Sentences 42000 of 103874\n",
      "Sentences 43000 of 103874\n",
      "Sentences 44000 of 103874\n",
      "Sentences 45000 of 103874\n",
      "Sentences 46000 of 103874\n",
      "Sentences 47000 of 103874\n",
      "Sentences 48000 of 103874\n",
      "Sentences 49000 of 103874\n",
      "Sentences 50000 of 103874\n",
      "Sentences 51000 of 103874\n",
      "Sentences 52000 of 103874\n",
      "Sentences 53000 of 103874\n",
      "Sentences 54000 of 103874\n",
      "Sentences 55000 of 103874\n",
      "Sentences 56000 of 103874\n",
      "Sentences 57000 of 103874\n",
      "Sentences 58000 of 103874\n",
      "Sentences 59000 of 103874\n",
      "Sentences 60000 of 103874\n",
      "Sentences 61000 of 103874\n",
      "Sentences 62000 of 103874\n",
      "Sentences 63000 of 103874\n",
      "Sentences 64000 of 103874\n",
      "Sentences 65000 of 103874\n",
      "Sentences 66000 of 103874\n",
      "Sentences 67000 of 103874\n",
      "Sentences 68000 of 103874\n",
      "Sentences 69000 of 103874\n",
      "Sentences 70000 of 103874\n",
      "Sentences 71000 of 103874\n",
      "Sentences 72000 of 103874\n",
      "Sentences 73000 of 103874\n",
      "Sentences 74000 of 103874\n",
      "Sentences 75000 of 103874\n",
      "Sentences 76000 of 103874\n",
      "Sentences 77000 of 103874\n",
      "Sentences 78000 of 103874\n",
      "Sentences 79000 of 103874\n",
      "Sentences 80000 of 103874\n",
      "Sentences 81000 of 103874\n",
      "Sentences 82000 of 103874\n",
      "Sentences 83000 of 103874\n",
      "Sentences 84000 of 103874\n",
      "Sentences 85000 of 103874\n",
      "Sentences 86000 of 103874\n",
      "Sentences 87000 of 103874\n",
      "Sentences 88000 of 103874\n",
      "Sentences 89000 of 103874\n",
      "Sentences 90000 of 103874\n",
      "Sentences 91000 of 103874\n",
      "Sentences 92000 of 103874\n",
      "Sentences 93000 of 103874\n",
      "Sentences 94000 of 103874\n",
      "Sentences 95000 of 103874\n",
      "Sentences 96000 of 103874\n",
      "Sentences 97000 of 103874\n",
      "Sentences 98000 of 103874\n",
      "Sentences 99000 of 103874\n",
      "Sentences 100000 of 103874\n",
      "Sentences 101000 of 103874\n",
      "Sentences 102000 of 103874\n",
      "Sentences 103000 of 103874\n",
      "11541\n",
      "---- Nomalizing ----\n",
      "11541\n",
      "Sentences 0 of 11541\n",
      "Sentences 1000 of 11541\n",
      "Sentences 2000 of 11541\n",
      "Sentences 3000 of 11541\n",
      "Sentences 4000 of 11541\n",
      "Sentences 5000 of 11541\n",
      "Sentences 6000 of 11541\n",
      "Sentences 7000 of 11541\n",
      "Sentences 8000 of 11541\n",
      "Sentences 9000 of 11541\n",
      "Sentences 10000 of 11541\n",
      "Sentences 11000 of 11541\n"
     ]
    }
   ],
   "source": [
    "num_features=100\n",
    "\n",
    "def nomalizer(sent):\n",
    "    only_letters=re.sub(\"[^a-zA-Z]\", \" \", sent)\n",
    "    tokens=nltk.word_tokenize(only_letters)[2:]\n",
    "    lower_case=[l.lower() for l in tokens]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    wordnet_lemmatizer=WordNetLemmatizer()\n",
    "    filtered_result=list(filter(lambda l: l not in stop_words, lower_case))\n",
    "    lemmas=[wordnet_lemmatizer.lemmatize(t) for t in filtered_result]\n",
    "    return lemmas\n",
    "\n",
    "# Generate a sentence vector by averaging words embeddings in a sentence\n",
    "def generate_sentence_vec(sentence, embeddings_dict, num_features):\n",
    "    sentence_vec=np.zeros(num_features,dtype=\"float32\")\n",
    "    num_words = 0\n",
    "    \n",
    "    embeddings_set=set(embeddings_dict.keys())\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word in embeddings_set:\n",
    "            num_words+=1\n",
    "            sentence_vec=np.add(sentence_vec, embeddings_dict[word])\n",
    "    \n",
    "    sentence_vec=np.divide(sentence_vec,num_words)\n",
    "    #print(sentence_vec)\n",
    "    return sentence_vec\n",
    "\n",
    "# Generate all senteneces vectors\n",
    "def generate_average_sentences_vec(sentences,embeddings_dict,num_features):\n",
    "    count=0\n",
    "    total_sent=len(sentences)\n",
    "    sentences_vec=np.zeros((len(sentences),num_features),dtype=\"float32\")\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if count % 1000 == 0:\n",
    "            print(\"Sentences {} of {}\".format(count,total_sent))\n",
    "\n",
    "        sentences_vec[count] = generate_sentence_vec(sentence, embeddings_dict, num_features)\n",
    "        count+=1\n",
    "\n",
    "    return sentences_vec\n",
    "\n",
    "def get_sentence_vectors(raw_data):\n",
    "    data = []\n",
    "    print(len(raw_data))\n",
    "    print(\"---- Nomalizing ----\")\n",
    "    for sent in raw_data:\n",
    "        data.append(nomalizer(sent))\n",
    "    \n",
    "    print(len(data))\n",
    "    X=generate_average_sentences_vec(data, embeddings_dict, num_features)\n",
    "    return X\n",
    "\n",
    "X_train_data = get_sentence_vectors(corpora_train_mod)\n",
    "X_test_data=get_sentence_vectors(corpora_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_train = X_train_data\n",
    "corpora_test = X_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from seaborn) (1.18.0)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from seaborn) (0.25.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from pandas>=0.22.0->seaborn) (2019.3)\n",
      "Requirement already satisfied: six in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /Users/happygirlzt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (44.0.0.post20200106)\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with SVM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import roc_curve, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(8,6))\n",
    "sns.countplot(y_train)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.show()\n",
    "#fig.savefig('original_distribution.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Forest accuray is 0.930248678624036\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-32c1edfc4875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrain_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Random_Forest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtrain_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Naive bayes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-32c1edfc4875>\u001b[0m in \u001b[0;36mtrain_clf\u001b[0;34m(name, clf, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_train_data=SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(X_train_data)\n",
    "X_test_data=SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Forest accuracy is 0.9285157265401611\n",
      "Random_Forest AUC is 0.9720607574743327\n",
      "SVC accuracy is 0.9289489645611299\n",
      "SVC AUC is 0.970989276025886\n",
      "Naive bayes accuracy is 0.8323368858851052\n",
      "Naive bayes AUC is 0.9111055702860418\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf=np.zeros(shape=(len(y_test),1))\n",
    "y_pred_svc=np.zeros(shape=(len(y_test),1))\n",
    "y_pred_nb=np.zeros(shape=(len(y_test),1))\n",
    "\n",
    "def train_clf(name, clf, y_pred, x_train, y_train, x_test, y_test):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    acc=accuracy_score(y_test, y_pred) \n",
    "\n",
    "    y_pred_proba = clf.predict_proba(x_test)\n",
    "    auc=roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "\n",
    "    \n",
    "    print(\"{} accuracy is {}\".format(name, acc))\n",
    "    print(\"{} AUC is {}\".format(name, auc))\n",
    "    \n",
    "train_clf('Random_Forest', RandomForestClassifier(), y_pred_rf,X_train_data,y_train,X_test_data,y_test)\n",
    "train_clf('SVC',SVC(gamma='auto',probability=True), y_pred_svc,X_train_data,y_train,X_test_data,y_test)\n",
    "train_clf('Naive bayes',GaussianNB(), y_pred_nb,X_train_data,y_train,X_test_data,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = [[int(list(doc[0])[1]),int(list(doc[0])[3])] for doc in pre_corpora_train]#vectorization Output\n",
    "target_test = [[int(list(doc[0])[1]),int(list(doc[0])[3])]for doc in pre_corpora_test]#vectorization Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_sentences_train = max([len(doc) for doc in corpora_train]) #<------- [Parameter]\n",
    "max_len_sentences_test = max([len(doc) for doc in corpora_test]) #<------- [Parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "84Y6sWgPKgkj",
    "outputId": "faf14c6d-926f-4256-b737-ce2541e30b73"
   },
   "outputs": [],
   "source": [
    "max_len_sentences = max(max_len_sentences_train,max_len_sentences_test)\n",
    "print(\"Max. Sentence # words:\",max_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len_sentences_train = min([len(doc) for doc in corpora_train]) #<------- [Parameter]\n",
    "min_len_sentences_test = min([len(doc) for doc in corpora_test]) #<------- [Parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DG6fdraDKjau",
    "outputId": "8f2ff01c-1374-465a-ca7c-c847320b1576"
   },
   "outputs": [],
   "source": [
    "min_len_sentences = max(min_len_sentences_train,min_len_sentences_test)\n",
    "print(\"Min. Sentence # words:\",min_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osMqB7LMKlCO"
   },
   "outputs": [],
   "source": [
    "embed_size = np.size(corpora_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKY-ieldfnVQ"
   },
   "source": [
    "### Designing Baseline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfQ2znRCK0MS"
   },
   "outputs": [],
   "source": [
    "#BaseLine Architecture <-------\n",
    "embeddigs_cols = embed_size\n",
    "input_sh = (max_len_sentences,embeddigs_cols,1)\n",
    "#Selecting filters? \n",
    "#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function\n",
    "#https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional\n",
    "\n",
    "N_filters = 128 # <-------- [HyperParameter] Powers of 2 Numer of Features\n",
    "K = 2 # <-------- [HyperParameter] Number of Classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZpBx4mEgK4oa",
    "outputId": "7f560cd1-0ddd-445d-bf57-61897832e267"
   },
   "outputs": [],
   "source": [
    "input_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "glpiGw14K-ch",
    "outputId": "32e23066-c2fd-451d-9656-6975beb6c229"
   },
   "outputs": [],
   "source": [
    "gram_input = Input(shape = input_sh)\n",
    "# 1st Convolutional Layer Convolutional Layer (7-gram)\n",
    "conv_1_layer = Conv2D(filters=32, input_shape=input_sh, activation='relu', \n",
    "                      kernel_size=(7,embeddigs_cols), padding='valid')(gram_input)\n",
    "conv_1_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CDLlKGWFLBQR",
    "outputId": "21426f83-311e-40d2-e163-1de09a6c1f37"
   },
   "outputs": [],
   "source": [
    "# Max Pooling \n",
    "max_1_pooling = MaxPooling2D(pool_size=((max_len_sentences-7+1),1), strides=None, padding='valid')(conv_1_layer)\n",
    "max_1_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NIPAYP28LDXv",
    "outputId": "1e24617f-9be5-41e9-faf7-11fc4f581204"
   },
   "outputs": [],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected_1_gram = Flatten()(max_1_pooling)\n",
    "fully_connected_1_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YL4Rk9RyLFBF",
    "outputId": "c80a8898-d8f7-436c-849a-401f0e737a05"
   },
   "outputs": [],
   "source": [
    "fully_connected_1_gram = Reshape((32, 1, 1))(fully_connected_1_gram)\n",
    "fully_connected_1_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "13c97VKNLIDs",
    "outputId": "daa22b71-3994-4d3d-e2aa-31dac4d3a07f"
   },
   "outputs": [],
   "source": [
    "# 2nd Convolutional Layer (5-gram)\n",
    "conv_2_layer = Conv2D(filters=64, kernel_size=(5,1), activation='relu', \n",
    "                      padding='valid')(fully_connected_1_gram)\n",
    "conv_2_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FoIm4mTZLKsx",
    "outputId": "7b1310c0-5e2d-4ceb-f9e2-3944c6162bbf"
   },
   "outputs": [],
   "source": [
    "max_2_pooling = MaxPooling2D(pool_size=((32-5+1),1), strides=None, padding='valid')(conv_2_layer)\n",
    "max_2_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3BUO38gRLMoy",
    "outputId": "9d497c9c-1e1f-491c-d2f1-0ea6030b9462"
   },
   "outputs": [],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected_2_gram = Flatten()(max_2_pooling)\n",
    "fully_connected_2_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m3t8vnrrLPDi",
    "outputId": "a9464f2a-ae71-4dcf-b2ab-306fc8cbaec8"
   },
   "outputs": [],
   "source": [
    "fully_connected_2_gram = Reshape((64, 1, 1))(fully_connected_2_gram)\n",
    "fully_connected_2_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TRBrLT6hLQ4x",
    "outputId": "aa9efea5-1983-4bc4-b6f5-2bd84e25b5f1"
   },
   "outputs": [],
   "source": [
    "# 3rd Convolutional Layer (3-gram)\n",
    "conv_3_layer =  Conv2D(filters=128, kernel_size=(3,1), activation='relu', \n",
    "                      padding='valid')(fully_connected_2_gram)\n",
    "conv_3_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3fqEy0OvLTo3",
    "outputId": "6599672b-dd13-47ed-b0b9-e3737456664a"
   },
   "outputs": [],
   "source": [
    "# 4th Convolutional Layer (3-gram)\n",
    "conv_4_layer = Conv2D(filters=128, kernel_size=(3,1), activation='relu', \n",
    "                     padding='valid')(conv_3_layer)\n",
    "conv_4_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wVv4RFv6LYYt",
    "outputId": "30eb2c76-c0e0-4153-8428-73f3493d5074"
   },
   "outputs": [],
   "source": [
    "# 5th Convolutional Layer (3-gram)\n",
    "conv_5_layer = Conv2D(filters=64, kernel_size=(3,1), activation='relu', \n",
    "                     padding='valid')(conv_4_layer)\n",
    "conv_5_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l4hqFvdHLaRZ",
    "outputId": "579163a8-4e80-42b4-bfad-0d467ac3eb31"
   },
   "outputs": [],
   "source": [
    "# Max Pooling\n",
    "max_5_pooling = MaxPooling2D(pool_size=(58,1), strides=None, padding='valid')(conv_5_layer)\n",
    "max_5_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tbgwf1kgLdzW",
    "outputId": "3b76a2b2-88a1-42db-d726-4c3c09de755a"
   },
   "outputs": [],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected = Flatten()(max_5_pooling)\n",
    "fully_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bc0USw7yLiBk",
    "outputId": "f5cbed89-d7a1-4938-c57f-0d40e8971b96"
   },
   "outputs": [],
   "source": [
    "# 1st Fully Connected Layer\n",
    "deep_dense_1_layer = Dense(32, activation='relu')(fully_connected)\n",
    "deep_dense_1_layer = Dropout(0.2)(deep_dense_1_layer) # <-------- [HyperParameter]\n",
    "deep_dense_1_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cPCwpofQLj5j",
    "outputId": "61eda5c0-c42b-4a99-d87a-ffc121e02f00"
   },
   "outputs": [],
   "source": [
    "# 2nd Fully Connected Layer\n",
    "deep_dense_2_layer = Dense(32, activation='relu')(deep_dense_1_layer)\n",
    "deep_dense_2_layer = Dropout(0.2)(deep_dense_2_layer) # <-------- [HyperParameter]\n",
    "deep_dense_2_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4PK2LvkbLrFJ",
    "outputId": "f23d53c1-b4cb-4b1f-9aec-1c4cb69c526d"
   },
   "outputs": [],
   "source": [
    "# 3rd Fully Connected Layer\n",
    "deep_dense_3_layer = Dense(16, activation='relu')(deep_dense_2_layer)\n",
    "deep_dense_3_layer = Dropout(0.2)(deep_dense_3_layer) # <-------- [HyperParameter]\n",
    "deep_dense_3_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjjeoJYGLwFp"
   },
   "outputs": [],
   "source": [
    "predictions = Dense(K, activation='softmax')(deep_dense_3_layer)\n",
    "#Criticality Model\n",
    "criticality_network = Model(inputs=[gram_input],outputs=[predictions]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "wmoUPuPqL2z3",
    "outputId": "7c749f96-777c-4cfb-afe0-b364195506d1"
   },
   "outputs": [],
   "source": [
    "print(criticality_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1v_kHaUL6mt"
   },
   "outputs": [],
   "source": [
    "#Seting up the Model\n",
    "criticality_network.compile(optimizer='adam',loss='binary_crossentropy',\n",
    "                                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQwpKXySMGBH"
   },
   "source": [
    "### Training the criticality network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-2N8Q80L-Yg"
   },
   "outputs": [],
   "source": [
    "#Data set organization\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0AY6LJaMRre"
   },
   "outputs": [],
   "source": [
    "#Memoization \n",
    "# file_corpora_train_x = path.join(mkdtemp(), '/content/gdrive/My Drive/Colab Notebooks/secure-req-net/alex-res-adapted-003_temp_corpora_train_x.dat') #Update per experiment\n",
    "# file_corpora_test_x = path.join(mkdtemp(), '/content/gdrive/My Drive/Colab Notebooks/secure-req-net/alex-res-adapted-003_temp_corpora_test_x.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Memoization \n",
    "file_corpora_train_x = path.join(mkdtemp(), 'train_x.dat') #Update per experiment\n",
    "file_corpora_test_x = path.join(mkdtemp(), 'test_x.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLzqqGd7MUwA"
   },
   "outputs": [],
   "source": [
    "#Shaping\n",
    "shape_train_x = (len(corpora_train),max_len_sentences,embeddigs_cols,1)\n",
    "shape_test_x = (len(corpora_test),max_len_sentences,embeddigs_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWvQjALqMZL4"
   },
   "outputs": [],
   "source": [
    "#Data sets\n",
    "corpora_train_x = np.memmap(\n",
    "        filename = file_corpora_train_x, \n",
    "        dtype='float32', \n",
    "        mode='w+', \n",
    "        shape = shape_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ivCP2HQlMdFQ"
   },
   "outputs": [],
   "source": [
    "corpora_test_x = np.memmap( #Test Corpora (for future evaluation)\n",
    "        filename = file_corpora_test_x, \n",
    "        dtype='float32', \n",
    "        mode='w+', \n",
    "        shape = shape_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZCT_mVRMflg"
   },
   "outputs": [],
   "source": [
    "target_train_y = np.array(target_train) #Train Target\n",
    "target_test_y = np.array(target_test) #Test Target (for future evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmIKpBK-MkkK",
    "outputId": "2f06ef40-0a27-4ff7-a3b1-de0f3147c31f"
   },
   "outputs": [],
   "source": [
    "print(corpora_train_x.shape, target_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TgDiguWEMnm0",
    "outputId": "3fc51011-77f2-4172-a39d-028a7936db81"
   },
   "outputs": [],
   "source": [
    "print(corpora_test_x.shape,target_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gtb-8-VMoYL"
   },
   "outputs": [],
   "source": [
    "#Reshaping Train Inputs\n",
    "for doc in range(len(corpora_train)):\n",
    "    #print(corpora_train[doc].shape[1])\n",
    "    for words_rows in range(corpora_train[doc].shape[0]):\n",
    "        embed_flatten = np.array(corpora_train[doc][words_rows]).flatten() #<--- Capture doc and word\n",
    "        for embedding_cols in range(embed_flatten.shape[0]):\n",
    "            corpora_train_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9hH0IbAMo5L"
   },
   "outputs": [],
   "source": [
    "#Reshaping Test Inputs (for future evaluation)\n",
    "for doc in range(len(corpora_test)):\n",
    "    for words_rows in range(corpora_test[doc].shape[0]):\n",
    "        embed_flatten = np.array(corpora_test[doc][words_rows]).flatten() #<--- Capture doc and word\n",
    "        for embedding_cols in range(embed_flatten.shape[0]):\n",
    "            corpora_test_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgHs7WwRNCNe"
   },
   "outputs": [],
   "source": [
    "#CheckPoints\n",
    "filepath = \"best_model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqB2PbvYNHFV"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "mc = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "callbacks_list = [es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(corpora_train_x)\n",
    "mask = np.random.choice(length, length, replace=False)\n",
    "# Use the same mask to maintain the shuffling sequence between data and labels\n",
    "shuffled_data = corpora_train_x[mask]\n",
    "shuffled_labels = target_train_y[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "30ahQNHeNIxg",
    "outputId": "d55fd7e2-a3b7-4adf-e744-2a1545d87af2"
   },
   "outputs": [],
   "source": [
    "#Model Fitting\n",
    "history = criticality_network.fit(\n",
    "            x = shuffled_data, \n",
    "            y = shuffled_labels,\n",
    "            batch_size=64,\n",
    "            epochs=40, #5 <------ Hyperparameter\n",
    "            validation_split = 0.2,\n",
    "            callbacks=callbacks_list,\n",
    "            shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_1 = 0\n",
    "count_2 = 0\n",
    "for i in target_train_y:\n",
    "    if i[0] == 1:\n",
    "        count_1 +=1 \n",
    "    else:\n",
    "        count_2 +=1\n",
    "print('{}, {}'.format(count_1, count_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xz8wz1ZPNKmP"
   },
   "outputs": [],
   "source": [
    "#Saving Training History\n",
    "df_history = pd.DataFrame.from_dict(history.history)\n",
    "df_history.to_csv('history_training.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "lmHTkzrZNQB7",
    "outputId": "9f7bdc82-5c94-47a3-9b9b-4b83ff83cb86"
   },
   "outputs": [],
   "source": [
    "criticality_network.save(filepath)\n",
    "df_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2FraZbmNWjH"
   },
   "outputs": [],
   "source": [
    "#Saving Test Data\n",
    "np.save('corpora_test_x.npy',corpora_test_x)\n",
    "np.save('target_test_y.npy',target_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_ZppHO9NcsA"
   },
   "source": [
    "### Partial Evaluation\n",
    "To make a deep evaluation, please refer to the \"evaluation\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "ngK3GrrRNp_h",
    "outputId": "223f1241-bb79-4130-99a4-ee02acf11bbf"
   },
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs2 = range(len(acc))\n",
    " \n",
    "plt.plot(epochs2, acc, 'b', label='Training')\n",
    "plt.plot(epochs2, val_acc, 'r', label='Validation')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs2, loss, 'b', label='Training')\n",
    "plt.plot(epochs2, val_loss, 'r', label='Validation')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKTt7z19TPYP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "alpha-securereqnet.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
