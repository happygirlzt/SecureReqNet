{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/danaderp/SecureReqNet/blob/master/alpha_securereqnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeZw_wJ0fvvF"
   },
   "source": [
    "## Alpha-SecureReqNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zweGRad_d4va"
   },
   "outputs": [],
   "source": [
    "#danaderp May6'19\n",
    "#Prediction For Main Issues Data Set \n",
    "#alpha-SecureReqNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tV4BxbkCfu09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happygirlzt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/dict_vectorizer.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "englishStemmer=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wMymf9NRaYNc",
    "outputId": "7daddf17-fc70-498d-d268-99f7a16d67b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/happygirlzt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "URHlMuyvgZsW",
    "outputId": "7161654a-f9e1-4ed0-e6a3-2e1d7e18a190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "#Importing Neural Dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dot, Input, Dense, Reshape, LSTM, Conv2D, Flatten, MaxPooling1D, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.layers import Embedding, Multiply, Subtract\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMqMwL02giiq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Ptsx9ghpqj_G",
    "outputId": "e4a072e0-27c7-4d19-fe16-2de980b90173"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGe5_Jx4K5WO"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/content/gdrive/My Drive/Colab Notebooks/secure-req-net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjEYU6Gw-K26"
   },
   "outputs": [],
   "source": [
    "#! unzip /content/gdrive/My\\ Drive/Colab\\ Notebooks/secure-req-net/datasets/augmented_dataset/augmented_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hQ6ctNB_uZ3"
   },
   "outputs": [],
   "source": [
    "#! cp -r issues/ /content/gdrive/My\\ Drive/Colab\\ Notebooks/secure-req-net/datasets/augmented_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.cells:\n",
    "                if cell.cell_type == 'code':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebook_utils.statistics.Embeddings as Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: nbpackage: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "ls nbpackage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPfRbyEiGdx-"
   },
   "outputs": [],
   "source": [
    "from data.read_data import Dynamic_Dataset\n",
    "from data.read_data import Processing_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sPpIvKEJQ5v"
   },
   "source": [
    "### Loading word embeddings from previous compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_risxO7JRmy"
   },
   "outputs": [],
   "source": [
    "path = \"data/augmented_dataset/\" #Place here the dataset you want to process\n",
    "process_unit = Processing_Dataset(path)\n",
    "ground_truth = process_unit.get_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "0XUh1VSTJqX2",
    "outputId": "ad2b28fc-7f93-4b75-9fd5-84ddb07cfbcf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11612 104510\n",
      "('(1,0)', 'In GNOME GLib 2.56.1, g_markup_parse_context_end_parse() in gmarkup.c has a NULL pointer dereference.') ('(1,0)', 'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/')\n"
     ]
    }
   ],
   "source": [
    "dataset = Dynamic_Dataset(ground_truth, path)\n",
    "test, train = process_unit.get_test_and_training(ground_truth)\n",
    "print(len(test),len(train))\n",
    "print(test[0],train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbNp-1h0KATi"
   },
   "outputs": [],
   "source": [
    "#Preprocesing Corpora\n",
    "embeddings = Embeddings\n",
    "max_words = 5000 #<------- [Parameter]\n",
    "pre_corpora_train = [doc for doc in train if len(doc[1])< max_words]\n",
    "pre_corpora_test = [doc for doc in test if len(doc[1])< max_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wCCf9WmwKFI-",
    "outputId": "8104a66d-f3cc-456b-8806-ef635620c2c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103877 11538\n"
     ]
    }
   ],
   "source": [
    "print(len(pre_corpora_train),len(pre_corpora_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3tbLvCR7KSmb"
   },
   "outputs": [],
   "source": [
    "#Loading embeddings\n",
    "# embed_path = '/content/gdrive/My Drive/Colab Notebooks/secure-req-net/datasets/augmented_dataset/word_embeddings-embed_size_100-epochs_100.csv'\n",
    "# embeddings_dict = embeddings.get_embeddings_dict(embed_path)\n",
    "# Does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17227\n",
      "Index(['use', 'user', 'version', 'test', 'file', 'secur', 'vulner', 'issu',\n",
      "       'allow', 'new',\n",
      "       ...\n",
      "       'enfield', 'hvidovr', 'madura', 'nonotak', 'bazeley', 'kunnam',\n",
      "       'steelesvill', 'pessoa', 'morisada', 'kuttin'],\n",
      "      dtype='object', length=17227)\n"
     ]
    }
   ],
   "source": [
    "# Rewrite cell above\n",
    "import pandas as pd\n",
    "embed_path = 'data/word_embeddings-embed_size_100-epochs_100.csv'\n",
    "df = pd.read_csv(embed_path)\n",
    "#print(df)\n",
    "cols = df.columns[1:]\n",
    "\n",
    "print(len(cols))\n",
    "print(cols)\n",
    "df.reset_index()\n",
    "embeddings_dict = {}\n",
    "for i in range(len(cols)):\n",
    "    #embedding_dict[cols[i]]\n",
    "    embeddings_dict[cols[i]] = list(df.iloc[:,i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 17228)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_dict['use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_corpora_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The currently used Rails version, in the stable branch, is insecure\\n\\nYou should update the Gemfile.lock to hotfix this.\\n\\nhttp://weblog.rubyonrails.org/2014/2/18/Rails_3_2_17_4_0_3_and_4_1_0_beta2_have_been_released/'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_corpora_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_train_mod = []\n",
    "Y_train_data=[]\n",
    "\n",
    "for row in pre_corpora_train:\n",
    "    corpora_train_mod.append(row[1])\n",
    "    Y_train_data.append(row[0])\n",
    "    \n",
    "corpora_test_mod=[]\n",
    "Y_test_data=[]\n",
    "for row in pre_corpora_test:\n",
    "    corpora_test_mod.append(row[1])\n",
    "    Y_test_data.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpora_train_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mUT1jXMKaR2"
   },
   "outputs": [],
   "source": [
    "#corpora_train = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_train]#vectorization Inputs\n",
    "#corpora_train=vectorizer.fit_transform(corpora_train_mod)\n",
    "#corpora_test=vectorizer.fit_transform(corpora_test_mod)\n",
    "#corpora_test = [embeddings.vectorize(doc[1], embeddings_dict) for doc in pre_corpora_test]#vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=100\n",
    "\n",
    "def nomalizer(sent):\n",
    "    only_letters=re.sub(\"[^a-zA-Z]\", \" \", sent)\n",
    "    tokens=nltk.word_tokenize(only_letters)[2:]\n",
    "    lower_case=[l.lower() for l in tokens]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    wordnet_lemmatizer=WordNetLemmatizer()\n",
    "    filtered_result=list(filter(lambda l: l not in stop_words, lower_case))\n",
    "    lemmas=[wordnet_lemmatizer.lemmatize(t) for t in filtered_result]\n",
    "    return lemmas\n",
    "\n",
    "# Generate a sentence vector by averaging words embeddings in a sentence\n",
    "def generate_sentence_vec(sentence, embeddings_dict, num_features):\n",
    "    sentence_vec=np.zeros(num_features,dtype=\"float32\")\n",
    "    num_words = 0\n",
    "    \n",
    "    embeddings_set=set(embeddings_dict.keys())\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word in embeddings_set:\n",
    "            num_words+=1\n",
    "            sentence_vec=np.add(sentence_vec, embeddings_dict[word])\n",
    "    \n",
    "    sentence_vec=np.divide(sentence_vec,num_words)\n",
    "    #print(sentence_vec)\n",
    "    return sentence_vec\n",
    "\n",
    "# Generate all senteneces vectors\n",
    "def generate_average_sentences_vec(sentences,embeddings_dict,num_features):\n",
    "    count=0\n",
    "    total_sent=len(sentences)\n",
    "    sentences_vec=np.zeros((len(sentences),num_features),dtype=\"float32\")\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if count % 1000 == 0:\n",
    "            print(\"Sentences {} of {}\".format(count,total_sent))\n",
    "\n",
    "        sentences_vec[count] = generate_sentence_vec(sentence, embeddings_dict, num_features)\n",
    "        count+=1\n",
    "\n",
    "    return sentences_vec\n",
    "\n",
    "def get_sentence_vectors(raw_data):\n",
    "    data = []\n",
    "    print(len(raw_data))\n",
    "    print(\"---- Nomalizing ----\")\n",
    "    for sent in raw_data:\n",
    "        data.append(nomalizer(sent))\n",
    "    \n",
    "    print(len(data))\n",
    "    X=generate_average_sentences_vec(data, embeddings_dict, num_features)\n",
    "    return X\n",
    "\n",
    "X_train_data = get_sentence_vectors(corpora_train_mod)\n",
    "X_test_data=get_sentence_vectors(corpora_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qd4ObDh0KbHM"
   },
   "outputs": [],
   "source": [
    "target_train = [[int(list(doc[0])[1]),int(list(doc[0])[3])] for doc in pre_corpora_train]#vectorization Output\n",
    "target_test = [[int(list(doc[0])[1]),int(list(doc[0])[3])]for doc in pre_corpora_test]#vectorization Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6GKIcOqKejD"
   },
   "outputs": [],
   "source": [
    "max_len_sentences_train = max([len(doc) for doc in corpora_train]) #<------- [Parameter]\n",
    "max_len_sentences_test = max([len(doc) for doc in corpora_test]) #<------- [Parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "84Y6sWgPKgkj",
    "outputId": "faf14c6d-926f-4256-b737-ce2541e30b73"
   },
   "outputs": [],
   "source": [
    "max_len_sentences = max(max_len_sentences_train,max_len_sentences_test)\n",
    "print(\"Max. Sentence # words:\",max_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_bTQ2ANKhjG"
   },
   "outputs": [],
   "source": [
    "min_len_sentences_train = min([len(doc) for doc in corpora_train]) #<------- [Parameter]\n",
    "min_len_sentences_test = min([len(doc) for doc in corpora_test]) #<------- [Parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DG6fdraDKjau",
    "outputId": "8f2ff01c-1374-465a-ca7c-c847320b1576"
   },
   "outputs": [],
   "source": [
    "min_len_sentences = max(min_len_sentences_train,min_len_sentences_test)\n",
    "print(\"Min. Sentence # words:\",min_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osMqB7LMKlCO"
   },
   "outputs": [],
   "source": [
    "embed_size = np.size(corpora_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKY-ieldfnVQ"
   },
   "source": [
    "### Designing Baseline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfQ2znRCK0MS"
   },
   "outputs": [],
   "source": [
    "#BaseLine Architecture <-------\n",
    "embeddigs_cols = embed_size\n",
    "input_sh = (max_len_sentences,embeddigs_cols,1)\n",
    "#Selecting filters? \n",
    "#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function\n",
    "#https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional\n",
    "\n",
    "N_filters = 128 # <-------- [HyperParameter] Powers of 2 Numer of Features\n",
    "K = 2 # <-------- [HyperParameter] Number of Classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZpBx4mEgK4oa",
    "outputId": "7f560cd1-0ddd-445d-bf57-61897832e267"
   },
   "outputs": [],
   "source": [
    "input_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "glpiGw14K-ch",
    "outputId": "32e23066-c2fd-451d-9656-6975beb6c229"
   },
   "outputs": [],
   "source": [
    "gram_input = Input(shape = input_sh)\n",
    "# 1st Convolutional Layer Convolutional Layer (7-gram)\n",
    "conv_1_layer = Conv2D(filters=32, input_shape=input_sh, activation='relu', \n",
    "                      kernel_size=(7,embeddigs_cols), padding='valid')(gram_input)\n",
    "conv_1_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CDLlKGWFLBQR",
    "outputId": "21426f83-311e-40d2-e163-1de09a6c1f37"
   },
   "outputs": [],
   "source": [
    "# Max Pooling \n",
    "max_1_pooling = MaxPooling2D(pool_size=((max_len_sentences-7+1),1), strides=None, padding='valid')(conv_1_layer)\n",
    "max_1_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NIPAYP28LDXv",
    "outputId": "1e24617f-9be5-41e9-faf7-11fc4f581204"
   },
   "outputs": [],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected_1_gram = Flatten()(max_1_pooling)\n",
    "fully_connected_1_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YL4Rk9RyLFBF",
    "outputId": "c80a8898-d8f7-436c-849a-401f0e737a05"
   },
   "outputs": [],
   "source": [
    "fully_connected_1_gram = Reshape((32, 1, 1))(fully_connected_1_gram)\n",
    "fully_connected_1_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "13c97VKNLIDs",
    "outputId": "daa22b71-3994-4d3d-e2aa-31dac4d3a07f"
   },
   "outputs": [],
   "source": [
    "# 2nd Convolutional Layer (5-gram)\n",
    "conv_2_layer = Conv2D(filters=64, kernel_size=(5,1), activation='relu', \n",
    "                      padding='valid')(fully_connected_1_gram)\n",
    "conv_2_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FoIm4mTZLKsx",
    "outputId": "7b1310c0-5e2d-4ceb-f9e2-3944c6162bbf"
   },
   "outputs": [],
   "source": [
    "max_2_pooling = MaxPooling2D(pool_size=((32-5+1),1), strides=None, padding='valid')(conv_2_layer)\n",
    "max_2_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3BUO38gRLMoy",
    "outputId": "9d497c9c-1e1f-491c-d2f1-0ea6030b9462"
   },
   "outputs": [],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected_2_gram = Flatten()(max_2_pooling)\n",
    "fully_connected_2_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m3t8vnrrLPDi",
    "outputId": "a9464f2a-ae71-4dcf-b2ab-306fc8cbaec8"
   },
   "outputs": [],
   "source": [
    "fully_connected_2_gram = Reshape((64, 1, 1))(fully_connected_2_gram)\n",
    "fully_connected_2_gram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TRBrLT6hLQ4x",
    "outputId": "aa9efea5-1983-4bc4-b6f5-2bd84e25b5f1"
   },
   "outputs": [],
   "source": [
    "# 3rd Convolutional Layer (3-gram)\n",
    "conv_3_layer =  Conv2D(filters=128, kernel_size=(3,1), activation='relu', \n",
    "                      padding='valid')(fully_connected_2_gram)\n",
    "conv_3_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3fqEy0OvLTo3",
    "outputId": "6599672b-dd13-47ed-b0b9-e3737456664a"
   },
   "outputs": [],
   "source": [
    "# 4th Convolutional Layer (3-gram)\n",
    "conv_4_layer = Conv2D(filters=128, kernel_size=(3,1), activation='relu', \n",
    "                     padding='valid')(conv_3_layer)\n",
    "conv_4_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wVv4RFv6LYYt",
    "outputId": "30eb2c76-c0e0-4153-8428-73f3493d5074"
   },
   "outputs": [],
   "source": [
    "# 5th Convolutional Layer (3-gram)\n",
    "conv_5_layer = Conv2D(filters=64, kernel_size=(3,1), activation='relu', \n",
    "                     padding='valid')(conv_4_layer)\n",
    "conv_5_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l4hqFvdHLaRZ",
    "outputId": "579163a8-4e80-42b4-bfad-0d467ac3eb31"
   },
   "outputs": [],
   "source": [
    "# Max Pooling\n",
    "max_5_pooling = MaxPooling2D(pool_size=(58,1), strides=None, padding='valid')(conv_5_layer)\n",
    "max_5_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tbgwf1kgLdzW",
    "outputId": "3b76a2b2-88a1-42db-d726-4c3c09de755a"
   },
   "outputs": [],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected = Flatten()(max_5_pooling)\n",
    "fully_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bc0USw7yLiBk",
    "outputId": "f5cbed89-d7a1-4938-c57f-0d40e8971b96"
   },
   "outputs": [],
   "source": [
    "# 1st Fully Connected Layer\n",
    "deep_dense_1_layer = Dense(32, activation='relu')(fully_connected)\n",
    "deep_dense_1_layer = Dropout(0.2)(deep_dense_1_layer) # <-------- [HyperParameter]\n",
    "deep_dense_1_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cPCwpofQLj5j",
    "outputId": "61eda5c0-c42b-4a99-d87a-ffc121e02f00"
   },
   "outputs": [],
   "source": [
    "# 2nd Fully Connected Layer\n",
    "deep_dense_2_layer = Dense(32, activation='relu')(deep_dense_1_layer)\n",
    "deep_dense_2_layer = Dropout(0.2)(deep_dense_2_layer) # <-------- [HyperParameter]\n",
    "deep_dense_2_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4PK2LvkbLrFJ",
    "outputId": "f23d53c1-b4cb-4b1f-9aec-1c4cb69c526d"
   },
   "outputs": [],
   "source": [
    "# 3rd Fully Connected Layer\n",
    "deep_dense_3_layer = Dense(16, activation='relu')(deep_dense_2_layer)\n",
    "deep_dense_3_layer = Dropout(0.2)(deep_dense_3_layer) # <-------- [HyperParameter]\n",
    "deep_dense_3_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjjeoJYGLwFp"
   },
   "outputs": [],
   "source": [
    "predictions = Dense(K, activation='softmax')(deep_dense_3_layer)\n",
    "#Criticality Model\n",
    "criticality_network = Model(inputs=[gram_input],outputs=[predictions]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "wmoUPuPqL2z3",
    "outputId": "7c749f96-777c-4cfb-afe0-b364195506d1"
   },
   "outputs": [],
   "source": [
    "print(criticality_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1v_kHaUL6mt"
   },
   "outputs": [],
   "source": [
    "#Seting up the Model\n",
    "criticality_network.compile(optimizer='adam',loss='binary_crossentropy',\n",
    "                                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQwpKXySMGBH"
   },
   "source": [
    "### Training the criticality network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-2N8Q80L-Yg"
   },
   "outputs": [],
   "source": [
    "#Data set organization\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0AY6LJaMRre"
   },
   "outputs": [],
   "source": [
    "#Memoization \n",
    "file_corpora_train_x = path.join(mkdtemp(), '/content/gdrive/My Drive/Colab Notebooks/secure-req-net/alex-res-adapted-003_temp_corpora_train_x.dat') #Update per experiment\n",
    "file_corpora_test_x = path.join(mkdtemp(), '/content/gdrive/My Drive/Colab Notebooks/secure-req-net/alex-res-adapted-003_temp_corpora_test_x.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLzqqGd7MUwA"
   },
   "outputs": [],
   "source": [
    "#Shaping\n",
    "shape_train_x = (len(corpora_train),max_len_sentences,embeddigs_cols,1)\n",
    "shape_test_x = (len(corpora_test),max_len_sentences,embeddigs_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWvQjALqMZL4"
   },
   "outputs": [],
   "source": [
    "#Data sets\n",
    "corpora_train_x = np.memmap(\n",
    "        filename = file_corpora_train_x, \n",
    "        dtype='float32', \n",
    "        mode='w+', \n",
    "        shape = shape_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ivCP2HQlMdFQ"
   },
   "outputs": [],
   "source": [
    "corpora_test_x = np.memmap( #Test Corpora (for future evaluation)\n",
    "        filename = file_corpora_test_x, \n",
    "        dtype='float32', \n",
    "        mode='w+', \n",
    "        shape = shape_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZCT_mVRMflg"
   },
   "outputs": [],
   "source": [
    "target_train_y = np.array(target_train) #Train Target\n",
    "target_test_y = np.array(target_test) #Test Target (for future evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmIKpBK-MkkK",
    "outputId": "2f06ef40-0a27-4ff7-a3b1-de0f3147c31f"
   },
   "outputs": [],
   "source": [
    "print(corpora_train_x.shape, target_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TgDiguWEMnm0",
    "outputId": "3fc51011-77f2-4172-a39d-028a7936db81"
   },
   "outputs": [],
   "source": [
    "print(corpora_test_x.shape,target_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gtb-8-VMoYL"
   },
   "outputs": [],
   "source": [
    "#Reshaping Train Inputs\n",
    "for doc in range(len(corpora_train)):\n",
    "    #print(corpora_train[doc].shape[1])\n",
    "    for words_rows in range(corpora_train[doc].shape[0]):\n",
    "        embed_flatten = np.array(corpora_train[doc][words_rows]).flatten() #<--- Capture doc and word\n",
    "        for embedding_cols in range(embed_flatten.shape[0]):\n",
    "            corpora_train_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9hH0IbAMo5L"
   },
   "outputs": [],
   "source": [
    "#Reshaping Test Inputs (for future evaluation)\n",
    "for doc in range(len(corpora_test)):\n",
    "    for words_rows in range(corpora_test[doc].shape[0]):\n",
    "        embed_flatten = np.array(corpora_test[doc][words_rows]).flatten() #<--- Capture doc and word\n",
    "        for embedding_cols in range(embed_flatten.shape[0]):\n",
    "            corpora_test_x[doc,words_rows,embedding_cols,0] = embed_flatten[embedding_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgHs7WwRNCNe"
   },
   "outputs": [],
   "source": [
    "#CheckPoints\n",
    "filepath = \"/content/gdrive/My Drive/Colab Notebooks/secure-req-net/best_model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqB2PbvYNHFV"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "mc = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "callbacks_list = [es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "30ahQNHeNIxg",
    "outputId": "d55fd7e2-a3b7-4adf-e744-2a1545d87af2"
   },
   "outputs": [],
   "source": [
    "#Model Fitting\n",
    "history = criticality_network.fit(\n",
    "            x = corpora_train_x, \n",
    "            y = target_train_y,\n",
    "            #batch_size=64,\n",
    "            epochs=1, #5 <------ Hyperparameter\n",
    "            validation_split = 0.2,\n",
    "            callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xz8wz1ZPNKmP"
   },
   "outputs": [],
   "source": [
    "#Saving Training History\n",
    "df_history = pd.DataFrame.from_dict(history.history)\n",
    "df_history.to_csv('/content/gdrive/My Drive/Colab Notebooks/secure-req-net/history_training.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "lmHTkzrZNQB7",
    "outputId": "9f7bdc82-5c94-47a3-9b9b-4b83ff83cb86"
   },
   "outputs": [],
   "source": [
    "criticality_network.save(filepath)\n",
    "df_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2FraZbmNWjH"
   },
   "outputs": [],
   "source": [
    "#Saving Test Data\n",
    "np.save('/content/gdrive/My Drive/Colab Notebooks/secure-req-net/corpora_test_x.npy',corpora_test_x)\n",
    "np.save('/content/gdrive/My Drive/Colab Notebooks/secure-req-net/target_test_y.npy',target_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_ZppHO9NcsA"
   },
   "source": [
    "### Partial Evaluation\n",
    "To make a deep evaluation, please refer to the \"evaluation\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "ngK3GrrRNp_h",
    "outputId": "223f1241-bb79-4130-99a4-ee02acf11bbf"
   },
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs2 = range(len(acc))\n",
    " \n",
    "plt.plot(epochs2, acc, 'b', label='Training')\n",
    "plt.plot(epochs2, val_acc, 'r', label='Validation')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs2, loss, 'b', label='Training')\n",
    "plt.plot(epochs2, val_loss, 'r', label='Validation')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKTt7z19TPYP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "alpha-securereqnet.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
