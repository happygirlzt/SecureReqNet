{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#danaderp March 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#Implementing the Skip-Gram Model\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_colwidth = 200\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "englishStemmer=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dot, Input, Dense, Reshape, LSTM, Conv2D, Flatten, MaxPooling1D, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.layers import Embedding, Multiply, Subtract\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Part O\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "remove_terms = punctuation + '0123456789'\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    #Filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    #Filtering Stemmings\n",
    "    filtered_tokens = [englishStemmer.stem(token) for token in filtered_tokens]\n",
    "    #Filtering remove-terms\n",
    "    filtered_tokens = [token for token in filtered_tokens if token not in remove_terms and len(token)>2]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing Part I\n",
    "remove_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Data\n",
    "filename = '../../data/cve/cve_dataset.tsv'\n",
    "data = []\n",
    "with open(filename, 'r') as tsv_file:\n",
    "    tsv_reader = csv.reader(tsv_file, delimiter='\\t')\n",
    "    for line in tsv_reader:\n",
    "        data.append((line[1], line[2]))\n",
    "\n",
    "# for d in data:\n",
    "#     print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A buffer overflow in InterScan VirusWall 3.23 and 3.3 allows a remote attacker to execute arbitrary code by sending a long HELO command to the server.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "#Create a Method\n",
    "corpora = [sentence[1] for sentence in data]\n",
    "norm_corpora = [sentence.split(' ') for sentence in corpora]\n",
    "norm_corpora = [[word.lower() for word in sent if word not in remove_terms] \n",
    "                for sent in norm_corpora]\n",
    "norm_corpora = [' '.join(tok_sent) for tok_sent in norm_corpora]\n",
    "norm_corpora = filter(None, normalize_corpus(norm_corpora))\n",
    "norm_corpora = [tok_sent for tok_sent in norm_corpora if len(tok_sent.split()) > 2] #Len of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-Building the corpus vocabulary\n",
    "tokenizer_corpora = text.Tokenizer()\n",
    "tokenizer_corpora.fit_on_texts(norm_corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = tokenizer_corpora.word_index\n",
    "id2word = {v:k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size Source: 17769\n",
      "Vocabulary Sample Source: [('vulner', 1), ('attack', 2), ('allow', 3), ('via', 4), ('remot', 5), ('version', 6), ('user', 7), ('execut', 8), ('file', 9), ('code', 10)]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2id) + 1 \n",
    "embed_size = 20 # <-------- [HyperParameter]\n",
    "print('Vocabulary Size Source:', vocab_size)\n",
    "print('Vocabulary Sample Source:', list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_corpora] #Vector of IDs of words per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-Build a skip-gram [(target, context), relevancy] generator\n",
    "# generate skip-grams\n",
    "#Window SIZE!\n",
    "w_size = 10 # <-------- [HyperParameter]\n",
    "skip_grams = [skipgrams(wid, vocabulary_size=vocab_size, window_size=w_size) for wid in wids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(arbitrari (11), mojarra (15455)) -> 0\n",
      "(code (10), viruswal (2395)) -> 1\n",
      "(code (10), interscan (2394)) -> 1\n",
      "(arbitrari (11), remot (5)) -> 1\n",
      "(arbitrari (11), attack (2)) -> 1\n",
      "(interscan (2394), xmplay (11979)) -> 0\n",
      "(viruswal (2395), remot (5)) -> 1\n",
      "(interscan (2394), allow (3)) -> 1\n",
      "(viruswal (2395), mpvimplmptrackfinishsdtp (13408)) -> 0\n",
      "(long (270), hugeit (1974)) -> 0\n"
     ]
    }
   ],
   "source": [
    "# view sample skip-grams\n",
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(10):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "          id2word[pairs[i][0]], pairs[i][0], \n",
    "          id2word[pairs[i][1]], pairs[i][1], \n",
    "          labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-Building the skip-gram model architecture\n",
    "#The functional API Version\n",
    "#Receive 1 Integer between 1 and embed_size\n",
    "word_input = Input(shape=(1,))\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense vocab_size-dimensional vectors.\n",
    "x_word = Embedding(vocab_size, embed_size,embeddings_initializer=\"glorot_uniform\",input_length=1)(word_input)\n",
    "x_word = Reshape((embed_size, ))(x_word)\n",
    "\n",
    "context_input = Input(shape=(1,))\n",
    "\n",
    "x_context = Embedding(vocab_size, embed_size,embeddings_initializer=\"glorot_uniform\",input_length=1)(context_input)\n",
    "x_context = Reshape((embed_size, ))(x_context)\n",
    "\n",
    "x = Dot(axes=-1,normalize=True)([x_word, x_context])\n",
    "x = Dense(1,kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining The model\n",
    "model = Model(inputs=[word_input,context_input], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Compiling\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 20)        355380      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 20)        355380      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 20)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 20)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           dot[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 710,762\n",
      "Trainable params: 710,762\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# view model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
    "#                  rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Source 0 (skip_first, skip_second, relevance) pairs\n",
      "Processed Source 10000 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 1 Loss: 1379.9965764218941\n",
      "Processed Source 0 (skip_first, skip_second, relevance) pairs\n",
      "Processed Source 10000 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 2 Loss: 1236.449962376384\n",
      "Processed Source 0 (skip_first, skip_second, relevance) pairs\n",
      "Processed Source 10000 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 3 Loss: 1201.1626591628883\n",
      "Processed Source 0 (skip_first, skip_second, relevance) pairs\n",
      "Processed Source 10000 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 4 Loss: 1163.254083123291\n",
      "Processed Source 0 (skip_first, skip_second, relevance) pairs\n",
      "Processed Source 10000 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 5 Loss: 1138.2745210702997\n"
     ]
    }
   ],
   "source": [
    "#4-Training The Model \n",
    "for epoch in range(1, 6):\n",
    "    loss = 0\n",
    "    for i, elem in enumerate(skip_grams):\n",
    "        pair_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
    "        pair_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
    "        labels = np.array(elem[1], dtype='int32')\n",
    "        X = [pair_first_elem, pair_second_elem]\n",
    "        Y = labels\n",
    "        if i % 10000 == 0:\n",
    "            print('Processed Source {} (skip_first, skip_second, relevance) pairs'.format(i))\n",
    "        loss += model.train_on_batch(X,Y)  \n",
    "    print('Epoch:', epoch, 'Loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-Getting Word Embeddings\n",
    "weights = model.layers[2].get_weights()[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.DataFrame(weights, index=id2word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vulner</th>\n",
       "      <td>0.029791</td>\n",
       "      <td>0.133402</td>\n",
       "      <td>-0.030531</td>\n",
       "      <td>-0.077273</td>\n",
       "      <td>0.099846</td>\n",
       "      <td>-0.378489</td>\n",
       "      <td>0.124145</td>\n",
       "      <td>-0.103751</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>-0.213379</td>\n",
       "      <td>-0.221962</td>\n",
       "      <td>0.150023</td>\n",
       "      <td>0.017552</td>\n",
       "      <td>0.037190</td>\n",
       "      <td>0.196109</td>\n",
       "      <td>-0.381737</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>-0.114640</td>\n",
       "      <td>-0.013800</td>\n",
       "      <td>-0.173971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attack</th>\n",
       "      <td>0.013942</td>\n",
       "      <td>0.234610</td>\n",
       "      <td>0.056856</td>\n",
       "      <td>-0.260750</td>\n",
       "      <td>-0.063968</td>\n",
       "      <td>-0.362577</td>\n",
       "      <td>0.113978</td>\n",
       "      <td>-0.110138</td>\n",
       "      <td>0.165290</td>\n",
       "      <td>-0.176965</td>\n",
       "      <td>-0.224727</td>\n",
       "      <td>0.162961</td>\n",
       "      <td>-0.056045</td>\n",
       "      <td>0.080904</td>\n",
       "      <td>0.200855</td>\n",
       "      <td>-0.384939</td>\n",
       "      <td>0.135859</td>\n",
       "      <td>-0.075946</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>-0.016448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allow</th>\n",
       "      <td>0.036851</td>\n",
       "      <td>0.323518</td>\n",
       "      <td>-0.019389</td>\n",
       "      <td>-0.079774</td>\n",
       "      <td>-0.079845</td>\n",
       "      <td>-0.334971</td>\n",
       "      <td>0.097989</td>\n",
       "      <td>-0.194124</td>\n",
       "      <td>0.223996</td>\n",
       "      <td>-0.149279</td>\n",
       "      <td>-0.224916</td>\n",
       "      <td>0.204998</td>\n",
       "      <td>-0.007673</td>\n",
       "      <td>0.042238</td>\n",
       "      <td>0.229974</td>\n",
       "      <td>-0.466071</td>\n",
       "      <td>0.125965</td>\n",
       "      <td>-0.047542</td>\n",
       "      <td>0.093861</td>\n",
       "      <td>0.023899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>via</th>\n",
       "      <td>0.122959</td>\n",
       "      <td>0.285991</td>\n",
       "      <td>-0.008764</td>\n",
       "      <td>-0.134726</td>\n",
       "      <td>0.035227</td>\n",
       "      <td>-0.184372</td>\n",
       "      <td>-0.066779</td>\n",
       "      <td>-0.041294</td>\n",
       "      <td>0.266346</td>\n",
       "      <td>-0.188186</td>\n",
       "      <td>-0.298111</td>\n",
       "      <td>0.039487</td>\n",
       "      <td>0.008895</td>\n",
       "      <td>0.076055</td>\n",
       "      <td>0.220647</td>\n",
       "      <td>-0.354262</td>\n",
       "      <td>0.225883</td>\n",
       "      <td>0.035820</td>\n",
       "      <td>0.083921</td>\n",
       "      <td>0.051572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remot</th>\n",
       "      <td>-0.178436</td>\n",
       "      <td>0.170578</td>\n",
       "      <td>-0.045827</td>\n",
       "      <td>-0.092004</td>\n",
       "      <td>0.072009</td>\n",
       "      <td>-0.105454</td>\n",
       "      <td>0.018407</td>\n",
       "      <td>-0.008805</td>\n",
       "      <td>0.167930</td>\n",
       "      <td>-0.023994</td>\n",
       "      <td>-0.215696</td>\n",
       "      <td>0.130754</td>\n",
       "      <td>-0.058881</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>0.247068</td>\n",
       "      <td>-0.400714</td>\n",
       "      <td>0.112339</td>\n",
       "      <td>-0.070633</td>\n",
       "      <td>0.104002</td>\n",
       "      <td>0.051430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>0.142980</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.019239</td>\n",
       "      <td>0.133466</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>-0.408795</td>\n",
       "      <td>0.097404</td>\n",
       "      <td>-0.008066</td>\n",
       "      <td>0.083735</td>\n",
       "      <td>-0.266642</td>\n",
       "      <td>-0.216913</td>\n",
       "      <td>0.081066</td>\n",
       "      <td>0.171277</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.194828</td>\n",
       "      <td>-0.344600</td>\n",
       "      <td>-0.208429</td>\n",
       "      <td>-0.181132</td>\n",
       "      <td>0.080950</td>\n",
       "      <td>-0.043104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <td>0.213590</td>\n",
       "      <td>0.199066</td>\n",
       "      <td>0.029191</td>\n",
       "      <td>-0.072005</td>\n",
       "      <td>-0.049742</td>\n",
       "      <td>-0.162005</td>\n",
       "      <td>0.163244</td>\n",
       "      <td>-0.142738</td>\n",
       "      <td>-0.006523</td>\n",
       "      <td>-0.051994</td>\n",
       "      <td>-0.087395</td>\n",
       "      <td>0.066964</td>\n",
       "      <td>-0.323411</td>\n",
       "      <td>-0.032205</td>\n",
       "      <td>0.033528</td>\n",
       "      <td>-0.452243</td>\n",
       "      <td>0.269656</td>\n",
       "      <td>-0.058042</td>\n",
       "      <td>0.013768</td>\n",
       "      <td>0.155761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>execut</th>\n",
       "      <td>-0.068598</td>\n",
       "      <td>0.125390</td>\n",
       "      <td>-0.110637</td>\n",
       "      <td>-0.225154</td>\n",
       "      <td>0.071871</td>\n",
       "      <td>-0.234684</td>\n",
       "      <td>-0.036759</td>\n",
       "      <td>-0.086871</td>\n",
       "      <td>-0.030107</td>\n",
       "      <td>-0.206565</td>\n",
       "      <td>-0.294544</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>-0.131859</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.221932</td>\n",
       "      <td>-0.294394</td>\n",
       "      <td>0.203144</td>\n",
       "      <td>-0.131436</td>\n",
       "      <td>0.012681</td>\n",
       "      <td>-0.043524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>0.171961</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>-0.061310</td>\n",
       "      <td>-0.224528</td>\n",
       "      <td>0.324022</td>\n",
       "      <td>-0.243994</td>\n",
       "      <td>0.035711</td>\n",
       "      <td>0.053293</td>\n",
       "      <td>-0.189319</td>\n",
       "      <td>-0.253849</td>\n",
       "      <td>-0.120267</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>-0.011839</td>\n",
       "      <td>0.056021</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.568118</td>\n",
       "      <td>0.322231</td>\n",
       "      <td>-0.002039</td>\n",
       "      <td>-0.060740</td>\n",
       "      <td>0.130291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>-0.095517</td>\n",
       "      <td>0.128321</td>\n",
       "      <td>-0.020802</td>\n",
       "      <td>-0.193695</td>\n",
       "      <td>0.093964</td>\n",
       "      <td>-0.138499</td>\n",
       "      <td>-0.047520</td>\n",
       "      <td>-0.027487</td>\n",
       "      <td>-0.032707</td>\n",
       "      <td>-0.151899</td>\n",
       "      <td>-0.268576</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>-0.137210</td>\n",
       "      <td>-0.016884</td>\n",
       "      <td>0.167489</td>\n",
       "      <td>-0.314732</td>\n",
       "      <td>0.162616</td>\n",
       "      <td>-0.069166</td>\n",
       "      <td>-0.034451</td>\n",
       "      <td>-0.025782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arbitrari</th>\n",
       "      <td>0.031156</td>\n",
       "      <td>0.380906</td>\n",
       "      <td>-0.074046</td>\n",
       "      <td>0.092879</td>\n",
       "      <td>0.045394</td>\n",
       "      <td>-0.043093</td>\n",
       "      <td>-0.148616</td>\n",
       "      <td>-0.295998</td>\n",
       "      <td>-0.113906</td>\n",
       "      <td>-0.124153</td>\n",
       "      <td>-0.177890</td>\n",
       "      <td>-0.012802</td>\n",
       "      <td>-0.123505</td>\n",
       "      <td>0.043213</td>\n",
       "      <td>0.116081</td>\n",
       "      <td>-0.395353</td>\n",
       "      <td>0.450949</td>\n",
       "      <td>-0.144469</td>\n",
       "      <td>0.265660</td>\n",
       "      <td>0.104440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issu</th>\n",
       "      <td>0.209452</td>\n",
       "      <td>-0.163609</td>\n",
       "      <td>0.052129</td>\n",
       "      <td>-0.047871</td>\n",
       "      <td>0.025383</td>\n",
       "      <td>-0.065928</td>\n",
       "      <td>-0.230550</td>\n",
       "      <td>0.256465</td>\n",
       "      <td>-0.181750</td>\n",
       "      <td>-0.140243</td>\n",
       "      <td>-0.070316</td>\n",
       "      <td>0.018258</td>\n",
       "      <td>0.058295</td>\n",
       "      <td>0.008226</td>\n",
       "      <td>0.325389</td>\n",
       "      <td>-0.370032</td>\n",
       "      <td>0.118582</td>\n",
       "      <td>0.070868</td>\n",
       "      <td>0.242809</td>\n",
       "      <td>0.143267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window</th>\n",
       "      <td>0.020299</td>\n",
       "      <td>0.027884</td>\n",
       "      <td>-0.065286</td>\n",
       "      <td>-0.051665</td>\n",
       "      <td>0.049791</td>\n",
       "      <td>-0.098816</td>\n",
       "      <td>-0.013144</td>\n",
       "      <td>-0.028040</td>\n",
       "      <td>0.025351</td>\n",
       "      <td>0.068512</td>\n",
       "      <td>-0.109441</td>\n",
       "      <td>0.070060</td>\n",
       "      <td>-0.151226</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.082325</td>\n",
       "      <td>-0.163408</td>\n",
       "      <td>-0.104390</td>\n",
       "      <td>-0.127020</td>\n",
       "      <td>-0.062471</td>\n",
       "      <td>0.017807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exploit</th>\n",
       "      <td>0.059897</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>0.053406</td>\n",
       "      <td>-0.123371</td>\n",
       "      <td>-0.007974</td>\n",
       "      <td>-0.185874</td>\n",
       "      <td>0.082806</td>\n",
       "      <td>-0.081616</td>\n",
       "      <td>0.067015</td>\n",
       "      <td>-0.162492</td>\n",
       "      <td>-0.174428</td>\n",
       "      <td>0.032603</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>-0.188048</td>\n",
       "      <td>-0.013688</td>\n",
       "      <td>-0.139205</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>-0.063404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>server</th>\n",
       "      <td>0.076487</td>\n",
       "      <td>0.099817</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>-0.174232</td>\n",
       "      <td>0.012656</td>\n",
       "      <td>-0.250222</td>\n",
       "      <td>0.093747</td>\n",
       "      <td>0.099356</td>\n",
       "      <td>0.216785</td>\n",
       "      <td>-0.081661</td>\n",
       "      <td>-0.234312</td>\n",
       "      <td>0.084455</td>\n",
       "      <td>-0.091694</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>0.172548</td>\n",
       "      <td>-0.358001</td>\n",
       "      <td>-0.084986</td>\n",
       "      <td>-0.117017</td>\n",
       "      <td>-0.092202</td>\n",
       "      <td>-0.012647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>-0.067981</td>\n",
       "      <td>0.137348</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>-0.116128</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>-0.281833</td>\n",
       "      <td>0.155958</td>\n",
       "      <td>0.072412</td>\n",
       "      <td>-0.164765</td>\n",
       "      <td>0.016468</td>\n",
       "      <td>-0.161414</td>\n",
       "      <td>0.076028</td>\n",
       "      <td>-0.071485</td>\n",
       "      <td>-0.036864</td>\n",
       "      <td>0.081616</td>\n",
       "      <td>-0.422988</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>-0.060985</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.072005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.059733</td>\n",
       "      <td>0.163940</td>\n",
       "      <td>0.018912</td>\n",
       "      <td>0.018966</td>\n",
       "      <td>0.061442</td>\n",
       "      <td>-0.048751</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>-0.183458</td>\n",
       "      <td>0.172434</td>\n",
       "      <td>0.070813</td>\n",
       "      <td>-0.089729</td>\n",
       "      <td>0.209797</td>\n",
       "      <td>-0.218003</td>\n",
       "      <td>-0.017632</td>\n",
       "      <td>-0.258182</td>\n",
       "      <td>-0.040602</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.213692</td>\n",
       "      <td>0.203875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>0.110635</td>\n",
       "      <td>0.178235</td>\n",
       "      <td>0.043077</td>\n",
       "      <td>-0.220355</td>\n",
       "      <td>-0.037568</td>\n",
       "      <td>-0.316610</td>\n",
       "      <td>0.156417</td>\n",
       "      <td>-0.156938</td>\n",
       "      <td>0.080257</td>\n",
       "      <td>-0.152520</td>\n",
       "      <td>-0.192875</td>\n",
       "      <td>0.133302</td>\n",
       "      <td>-0.049734</td>\n",
       "      <td>0.079041</td>\n",
       "      <td>0.133679</td>\n",
       "      <td>-0.331220</td>\n",
       "      <td>-0.098039</td>\n",
       "      <td>-0.097430</td>\n",
       "      <td>-0.075151</td>\n",
       "      <td>0.014473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earlier</th>\n",
       "      <td>-0.033937</td>\n",
       "      <td>0.099313</td>\n",
       "      <td>-0.078685</td>\n",
       "      <td>0.124555</td>\n",
       "      <td>0.060882</td>\n",
       "      <td>-0.159885</td>\n",
       "      <td>-0.025889</td>\n",
       "      <td>-0.084544</td>\n",
       "      <td>-0.125528</td>\n",
       "      <td>-0.060770</td>\n",
       "      <td>-0.174598</td>\n",
       "      <td>-0.033636</td>\n",
       "      <td>0.098232</td>\n",
       "      <td>0.039950</td>\n",
       "      <td>-0.032186</td>\n",
       "      <td>-0.104763</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>-0.124372</td>\n",
       "      <td>0.142371</td>\n",
       "      <td>-0.004354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>servic</th>\n",
       "      <td>0.045642</td>\n",
       "      <td>0.014441</td>\n",
       "      <td>0.090382</td>\n",
       "      <td>-0.297183</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>-0.128734</td>\n",
       "      <td>0.041721</td>\n",
       "      <td>0.120099</td>\n",
       "      <td>-0.165957</td>\n",
       "      <td>-0.009880</td>\n",
       "      <td>-0.274881</td>\n",
       "      <td>0.095149</td>\n",
       "      <td>0.230676</td>\n",
       "      <td>-0.096890</td>\n",
       "      <td>0.187758</td>\n",
       "      <td>-0.569727</td>\n",
       "      <td>-0.084381</td>\n",
       "      <td>-0.050230</td>\n",
       "      <td>-0.109351</td>\n",
       "      <td>0.165549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5  \\\n",
       "vulner     0.029791  0.133402 -0.030531 -0.077273  0.099846 -0.378489   \n",
       "attack     0.013942  0.234610  0.056856 -0.260750 -0.063968 -0.362577   \n",
       "allow      0.036851  0.323518 -0.019389 -0.079774 -0.079845 -0.334971   \n",
       "via        0.122959  0.285991 -0.008764 -0.134726  0.035227 -0.184372   \n",
       "remot     -0.178436  0.170578 -0.045827 -0.092004  0.072009 -0.105454   \n",
       "version    0.142980  0.145600  0.019239  0.133466  0.016297 -0.408795   \n",
       "user       0.213590  0.199066  0.029191 -0.072005 -0.049742 -0.162005   \n",
       "execut    -0.068598  0.125390 -0.110637 -0.225154  0.071871 -0.234684   \n",
       "file       0.171961  0.058520 -0.061310 -0.224528  0.324022 -0.243994   \n",
       "code      -0.095517  0.128321 -0.020802 -0.193695  0.093964 -0.138499   \n",
       "arbitrari  0.031156  0.380906 -0.074046  0.092879  0.045394 -0.043093   \n",
       "issu       0.209452 -0.163609  0.052129 -0.047871  0.025383 -0.065928   \n",
       "window     0.020299  0.027884 -0.065286 -0.051665  0.049791 -0.098816   \n",
       "exploit    0.059897  0.143752  0.053406 -0.123371 -0.007974 -0.185874   \n",
       "server     0.076487  0.099817  0.019624 -0.174232  0.012656 -0.250222   \n",
       "could     -0.067981  0.137348  0.023370 -0.116128  0.010520 -0.281833   \n",
       "function   0.004001  0.059733  0.163940  0.018912  0.018966  0.061442   \n",
       "access     0.110635  0.178235  0.043077 -0.220355 -0.037568 -0.316610   \n",
       "earlier   -0.033937  0.099313 -0.078685  0.124555  0.060882 -0.159885   \n",
       "servic     0.045642  0.014441  0.090382 -0.297183  0.010307 -0.128734   \n",
       "\n",
       "                  6         7         8         9        10        11  \\\n",
       "vulner     0.124145 -0.103751  0.178344 -0.213379 -0.221962  0.150023   \n",
       "attack     0.113978 -0.110138  0.165290 -0.176965 -0.224727  0.162961   \n",
       "allow      0.097989 -0.194124  0.223996 -0.149279 -0.224916  0.204998   \n",
       "via       -0.066779 -0.041294  0.266346 -0.188186 -0.298111  0.039487   \n",
       "remot      0.018407 -0.008805  0.167930 -0.023994 -0.215696  0.130754   \n",
       "version    0.097404 -0.008066  0.083735 -0.266642 -0.216913  0.081066   \n",
       "user       0.163244 -0.142738 -0.006523 -0.051994 -0.087395  0.066964   \n",
       "execut    -0.036759 -0.086871 -0.030107 -0.206565 -0.294544  0.135542   \n",
       "file       0.035711  0.053293 -0.189319 -0.253849 -0.120267  0.056882   \n",
       "code      -0.047520 -0.027487 -0.032707 -0.151899 -0.268576  0.115950   \n",
       "arbitrari -0.148616 -0.295998 -0.113906 -0.124153 -0.177890 -0.012802   \n",
       "issu      -0.230550  0.256465 -0.181750 -0.140243 -0.070316  0.018258   \n",
       "window    -0.013144 -0.028040  0.025351  0.068512 -0.109441  0.070060   \n",
       "exploit    0.082806 -0.081616  0.067015 -0.162492 -0.174428  0.032603   \n",
       "server     0.093747  0.099356  0.216785 -0.081661 -0.234312  0.084455   \n",
       "could      0.155958  0.072412 -0.164765  0.016468 -0.161414  0.076028   \n",
       "function  -0.048751  0.006491 -0.183458  0.172434  0.070813 -0.089729   \n",
       "access     0.156417 -0.156938  0.080257 -0.152520 -0.192875  0.133302   \n",
       "earlier   -0.025889 -0.084544 -0.125528 -0.060770 -0.174598 -0.033636   \n",
       "servic     0.041721  0.120099 -0.165957 -0.009880 -0.274881  0.095149   \n",
       "\n",
       "                 12        13        14        15        16        17  \\\n",
       "vulner     0.017552  0.037190  0.196109 -0.381737  0.043154 -0.114640   \n",
       "attack    -0.056045  0.080904  0.200855 -0.384939  0.135859 -0.075946   \n",
       "allow     -0.007673  0.042238  0.229974 -0.466071  0.125965 -0.047542   \n",
       "via        0.008895  0.076055  0.220647 -0.354262  0.225883  0.035820   \n",
       "remot     -0.058881 -0.000706  0.247068 -0.400714  0.112339 -0.070633   \n",
       "version    0.171277  0.032684  0.194828 -0.344600 -0.208429 -0.181132   \n",
       "user      -0.323411 -0.032205  0.033528 -0.452243  0.269656 -0.058042   \n",
       "execut    -0.131859  0.021672  0.221932 -0.294394  0.203144 -0.131436   \n",
       "file      -0.011839  0.056021  0.051500 -0.568118  0.322231 -0.002039   \n",
       "code      -0.137210 -0.016884  0.167489 -0.314732  0.162616 -0.069166   \n",
       "arbitrari -0.123505  0.043213  0.116081 -0.395353  0.450949 -0.144469   \n",
       "issu       0.058295  0.008226  0.325389 -0.370032  0.118582  0.070868   \n",
       "window    -0.151226  0.010722  0.082325 -0.163408 -0.104390 -0.127020   \n",
       "exploit    0.005301  0.004084  0.011453 -0.188048 -0.013688 -0.139205   \n",
       "server    -0.091694  0.013044  0.172548 -0.358001 -0.084986 -0.117017   \n",
       "could     -0.071485 -0.036864  0.081616 -0.422988  0.016194 -0.060985   \n",
       "function   0.209797 -0.218003 -0.017632 -0.258182 -0.040602  0.003644   \n",
       "access    -0.049734  0.079041  0.133679 -0.331220 -0.098039 -0.097430   \n",
       "earlier    0.098232  0.039950 -0.032186 -0.104763  0.004937 -0.124372   \n",
       "servic     0.230676 -0.096890  0.187758 -0.569727 -0.084381 -0.050230   \n",
       "\n",
       "                 18        19  \n",
       "vulner    -0.013800 -0.173971  \n",
       "attack     0.021515 -0.016448  \n",
       "allow      0.093861  0.023899  \n",
       "via        0.083921  0.051572  \n",
       "remot      0.104002  0.051430  \n",
       "version    0.080950 -0.043104  \n",
       "user       0.013768  0.155761  \n",
       "execut     0.012681 -0.043524  \n",
       "file      -0.060740  0.130291  \n",
       "code      -0.034451 -0.025782  \n",
       "arbitrari  0.265660  0.104440  \n",
       "issu       0.242809  0.143267  \n",
       "window    -0.062471  0.017807  \n",
       "exploit    0.002977 -0.063404  \n",
       "server    -0.092202 -0.012647  \n",
       "could      0.011505  0.072005  \n",
       "function   0.213692  0.203875  \n",
       "access    -0.075151  0.014473  \n",
       "earlier    0.142371 -0.004354  \n",
       "servic    -0.109351  0.165549  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding_trans = df_embeddings.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vulner</th>\n",
       "      <th>attack</th>\n",
       "      <th>allow</th>\n",
       "      <th>via</th>\n",
       "      <th>remot</th>\n",
       "      <th>version</th>\n",
       "      <th>user</th>\n",
       "      <th>execut</th>\n",
       "      <th>file</th>\n",
       "      <th>code</th>\n",
       "      <th>...</th>\n",
       "      <th>spa</th>\n",
       "      <th>tikiusertasksphp</th>\n",
       "      <th>showhistori</th>\n",
       "      <th>phpseriala</th>\n",
       "      <th>esal</th>\n",
       "      <th>synchoxid</th>\n",
       "      <th>oxconfiggetrequestparamet</th>\n",
       "      <th>coreoxconfigphp</th>\n",
       "      <th>woocommercephp</th>\n",
       "      <th>dexpress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029791</td>\n",
       "      <td>0.013942</td>\n",
       "      <td>0.036851</td>\n",
       "      <td>0.122959</td>\n",
       "      <td>-0.178436</td>\n",
       "      <td>0.142980</td>\n",
       "      <td>0.213590</td>\n",
       "      <td>-0.068598</td>\n",
       "      <td>0.171961</td>\n",
       "      <td>-0.095517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>-0.008440</td>\n",
       "      <td>-0.002869</td>\n",
       "      <td>0.008051</td>\n",
       "      <td>0.020373</td>\n",
       "      <td>-0.007141</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>-0.001740</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>-0.009141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133402</td>\n",
       "      <td>0.234610</td>\n",
       "      <td>0.323518</td>\n",
       "      <td>0.285991</td>\n",
       "      <td>0.170578</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.199066</td>\n",
       "      <td>0.125390</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>0.128321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020110</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.025388</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.012541</td>\n",
       "      <td>-0.018431</td>\n",
       "      <td>0.013817</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>-0.005569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.030531</td>\n",
       "      <td>0.056856</td>\n",
       "      <td>-0.019389</td>\n",
       "      <td>-0.008764</td>\n",
       "      <td>-0.045827</td>\n",
       "      <td>0.019239</td>\n",
       "      <td>0.029191</td>\n",
       "      <td>-0.110637</td>\n",
       "      <td>-0.061310</td>\n",
       "      <td>-0.020802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009758</td>\n",
       "      <td>-0.004416</td>\n",
       "      <td>-0.013180</td>\n",
       "      <td>-0.009703</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>-0.014804</td>\n",
       "      <td>-0.012699</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.012613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.077273</td>\n",
       "      <td>-0.260750</td>\n",
       "      <td>-0.079774</td>\n",
       "      <td>-0.134726</td>\n",
       "      <td>-0.092004</td>\n",
       "      <td>0.133466</td>\n",
       "      <td>-0.072005</td>\n",
       "      <td>-0.225154</td>\n",
       "      <td>-0.224528</td>\n",
       "      <td>-0.193695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033600</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>-0.017977</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>-0.008351</td>\n",
       "      <td>-0.021678</td>\n",
       "      <td>-0.018960</td>\n",
       "      <td>-0.003657</td>\n",
       "      <td>-0.027119</td>\n",
       "      <td>-0.006125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099846</td>\n",
       "      <td>-0.063968</td>\n",
       "      <td>-0.079845</td>\n",
       "      <td>0.035227</td>\n",
       "      <td>0.072009</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>-0.049742</td>\n",
       "      <td>0.071871</td>\n",
       "      <td>0.324022</td>\n",
       "      <td>0.093964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010794</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.012404</td>\n",
       "      <td>0.026554</td>\n",
       "      <td>0.023507</td>\n",
       "      <td>0.013215</td>\n",
       "      <td>-0.010389</td>\n",
       "      <td>-0.003051</td>\n",
       "      <td>-0.014120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     vulner    attack     allow       via     remot   version      user  \\\n",
       "0  0.029791  0.013942  0.036851  0.122959 -0.178436  0.142980  0.213590   \n",
       "1  0.133402  0.234610  0.323518  0.285991  0.170578  0.145600  0.199066   \n",
       "2 -0.030531  0.056856 -0.019389 -0.008764 -0.045827  0.019239  0.029191   \n",
       "3 -0.077273 -0.260750 -0.079774 -0.134726 -0.092004  0.133466 -0.072005   \n",
       "4  0.099846 -0.063968 -0.079845  0.035227  0.072009  0.016297 -0.049742   \n",
       "\n",
       "     execut      file      code  ...       spa  tikiusertasksphp  showhistori  \\\n",
       "0 -0.068598  0.171961 -0.095517  ...  0.021281         -0.008440    -0.002869   \n",
       "1  0.125390  0.058520  0.128321  ... -0.020110         -0.002571    -0.025388   \n",
       "2 -0.110637 -0.061310 -0.020802  ... -0.009758         -0.004416    -0.013180   \n",
       "3 -0.225154 -0.224528 -0.193695  ... -0.033600          0.003005    -0.017977   \n",
       "4  0.071871  0.324022  0.093964  ...  0.010794          0.002342     0.000017   \n",
       "\n",
       "   phpseriala      esal  synchoxid  oxconfiggetrequestparamet  \\\n",
       "0    0.008051  0.020373  -0.007141                   0.011227   \n",
       "1    0.004379  0.012541  -0.018431                   0.013817   \n",
       "2   -0.009703  0.007223   0.008143                  -0.014804   \n",
       "3   -0.013000 -0.008351  -0.021678                  -0.018960   \n",
       "4   -0.012404  0.026554   0.023507                   0.013215   \n",
       "\n",
       "   coreoxconfigphp  woocommercephp  dexpress  \n",
       "0        -0.001740        0.015518 -0.009141  \n",
       "1         0.004595        0.008209 -0.005569  \n",
       "2        -0.012699        0.014299  0.012613  \n",
       "3        -0.003657       -0.027119 -0.006125  \n",
       "4        -0.010389       -0.003051 -0.014120  \n",
       "\n",
       "[5 rows x 17768 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02979121,  0.13340162, -0.03053069, -0.07727258,  0.09984584,\n",
       "       -0.37848935,  0.12414527, -0.10375053,  0.17834395, -0.21337855,\n",
       "       -0.22196162,  0.15002255,  0.0175519 ,  0.03719021,  0.19610938,\n",
       "       -0.38173738,  0.04315442, -0.11464024, -0.01379974, -0.17397141],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df_embedding_trans['vulner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17768, 17768)\n"
     ]
    }
   ],
   "source": [
    "#Verifying Closeness\n",
    "distance_matrix = euclidean_distances(weights)\n",
    "print(distance_matrix.shape)\n",
    "\n",
    "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:4]+1] \n",
    "                   for search_term in ['vulner', 'attack', 'window', 'via', 'remot', 'code', 'user','exploit']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17768"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vulner': ['attack', 'access', 'allow'],\n",
       " 'attack': ['allow', 'access', 'vulner'],\n",
       " 'window': ['microsoft', 'fail', 'elev'],\n",
       " 'via': ['allow', 'attack', 'request'],\n",
       " 'remot': ['code', 'aka', 'execut'],\n",
       " 'code': ['execut', 'remot', 'local'],\n",
       " 'user': ['system', 'authent', 'obtain'],\n",
       " 'exploit': ['success', 'unauthor', 'avail']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sum([[k] + v for k, v in similar_words.items()], [])\n",
    "words_ids = [word2id[w] for w in words]\n",
    "word_vectors = np.array([weights[idx] for idx in words_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-SNE dimensionality Reduction\n",
    "tsne = TSNE(n_components=2, random_state=0, n_iter=10000, perplexity=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(word_vectors)\n",
    "labels = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 32 \tWord Embedding shapes: (32, 20)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(T[:, 0], T[:, 1], c='steelblue', edgecolors='k')\n",
    "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')\n",
    "print('Total words:', len(words), '\\tWord Embedding shapes:', word_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. Sentence # words: 367\n"
     ]
    }
   ],
   "source": [
    "#Generating Training Set\n",
    "max_len_sentences = max([len(wpt.tokenize(doc)) for doc in norm_corpora]) #<------- [Parameter]\n",
    "print(\"Max. Sentence # words:\",max_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_tensor = [[np.array(df_embedding_trans[word_]) for word_ in wpt.tokenize(doc) if word_ not in remove_terms] \n",
    "                  for doc in norm_corpora]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wpt.tokenize(norm_corpora[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BaseLine Architecture <-------\n",
    "words_rows = max_len_sentences\n",
    "embeddigs_cols = embed_size\n",
    "input_sh = (words_rows,embeddigs_cols,1)\n",
    "#Selecting filters? \n",
    "#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function\n",
    "#https://stats.stackexchange.com/questions/196646/what-is-the-significance-of-the-number-of-convolution-filters-in-a-convolutional\n",
    "\n",
    "N_filters = 32 # <-------- [HyperParameter] Powers of 2 Numer of Features\n",
    "K = 2 # <-------- [HyperParameter] Number of Classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 20, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline_model = Sequential()\n",
    "gram_input = Input(shape = input_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st Convolutional Layer (1-gram)\n",
    "conv_filter_1_gram = Conv2D(filters= N_filters, input_shape=input_sh, activation='relu', \n",
    "                       kernel_size=(1,embeddigs_cols), padding='valid',data_format=\"channels_last\")(gram_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d/Identity:0' shape=(None, 367, 1, 32) dtype=float32>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_filter_1_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2sd Convolutional Layer (3-gram)\n",
    "conv_filter_3_gram = Conv2D(filters= N_filters, input_shape=input_sh, activation='relu', \n",
    "                       kernel_size=(3,embeddigs_cols), padding='valid')(gram_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd Convolutional Layer (5-gram)\n",
    "conv_filter_5_gram = Conv2D(filters= N_filters, input_shape=input_sh, activation='relu', \n",
    "                       kernel_size=(5,embeddigs_cols), padding='valid')(gram_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling Layer\n",
    "max_pool_1_gram = MaxPooling2D(pool_size=((words_rows-1+1), 1), strides=None, padding='valid')(conv_filter_1_gram)\n",
    "max_pool_3_gram = MaxPooling2D(pool_size=((words_rows-3+1), 1), strides=None, padding='valid')(conv_filter_3_gram)\n",
    "max_pool_5_gram = MaxPooling2D(pool_size=((words_rows-5+1), 1), strides=None, padding='valid')(conv_filter_5_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected layer\n",
    "fully_connected_1_gram = Flatten()(max_pool_1_gram)\n",
    "fully_connected_3_gram = Flatten()(max_pool_3_gram)\n",
    "fully_connected_5_gram = Flatten()(max_pool_5_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_vector = layers.concatenate([fully_connected_1_gram, fully_connected_3_gram, \n",
    "                                    fully_connected_5_gram], axis=-1)\n",
    "\n",
    "integration_layer = Dropout(0.4)(merged_vector)\n",
    "\n",
    "predictions = Dense(K, activation='softmax')(integration_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criticality Model\n",
    "criticality_network = Model(inputs=[gram_input],outputs=[predictions]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "criticality_network.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corpus Generation\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
